{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#确保下载的权值文件和这个ipython文件再同一个文件夹里面，或者自己指定绝对路径\n",
    "MODEL_ADDR=r'bvlc_alexnet.npy'\n",
    "import tensorflow as tf\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imresize\n",
    "from class_name import class_names\n",
    "import time\n",
    "#               conv1     conv2      conv3       conv4     conv5    fc6   fc7     fc8\n",
    "variable_trable=[False,    False,     False,    False,    False,  False,  True,  True,]\n",
    "variable_trable=[None]+variable_trable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv(input, kernel, biases, c_o, s_h, s_w, padding=\"VALID\", group=1):\n",
    "    '''From https://github.com/ethereon/caffe-tensorflow\n",
    "    '''\n",
    "    c_i = input.get_shape()[-1]\n",
    "    convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\n",
    "    if group == 1:\n",
    "        #不对输入分组卷积\n",
    "        conv = convolve(input, kernel)\n",
    "    else:\n",
    "        #将输入平分成group组，按[N,w,h,channel]->[0,1,2,3]也就是按输入的channel来分成两个矩阵\n",
    "        input_groups = tf.split(input, group, 3)  # tf.split(3, group, input)\n",
    "        #将卷积核平分成group组，按[w,h,in_channel,out_channel]->[0,1,2,3]也就是按输入的channel来分成两个矩阵\n",
    "        kernel_groups = tf.split(kernel, group, 3)  # tf.split(3, group, kernel)\n",
    "        #分组卷积\n",
    "        output_groups = [convolve(i, k) for i, k in zip(input_groups, kernel_groups)]\n",
    "        #连接卷积的结果\n",
    "        conv = tf.concat(output_groups, 3)  # tf.concat(3, output_groups)\n",
    "    return conv + biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lrn(x):\n",
    "    #return x\n",
    "    #lrn层，现在比较少用，一般用bn层代替\n",
    "    return tf.nn.local_response_normalization(x,\n",
    "                                              depth_radius=2,\n",
    "                                              alpha=2e-05,\n",
    "                                              beta=0.75,\n",
    "                                              bias=1.0)\n",
    "def maxpool(x):\n",
    "    #因为alex net 用到的maxpool都是一样的参数，所以直接写以函数代替，不用填参数\n",
    "    return tf.nn.max_pool(x, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_model_weight_and_biases():\n",
    "    '''\n",
    "    读取模型中的变量值，返回训练好的权重\n",
    "    model_addr：模型的路径\n",
    "    '''\n",
    "    weights_dict = np.load(MODEL_ADDR, encoding='bytes').item()\n",
    "    return weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def alexnet(x,net_data,keep_prob):#提取特征的时候train=False\n",
    "    #layer_1 conv1-relu-lrn-maxpool\n",
    "   \n",
    "    with tf.name_scope('layer_1'):\n",
    "        CONV1_W,CONV1_b=tf.Variable(net_data['conv1'][0],name='conv1_w',trainable=variable_trable[1]),\\\n",
    "        tf.Variable(net_data['conv1'][1],name='conv1_b',trainable=variable_trable[1])\n",
    "        conv1_=conv(X, CONV1_W, CONV1_b, c_o=96, s_h=4, s_w=4, padding=\"VALID\", group=1)\n",
    "        relu1_=tf.nn.relu(conv1_)\n",
    "        norm1=lrn(relu1_)\n",
    "        maxpool1_=maxpool(norm1)\n",
    "        \n",
    "    #layer_2 conv2-relu-lrn-maxpool\n",
    "    with tf.name_scope('layer_2'):\n",
    "        CONV2_W,CONV2_b=tf.Variable(net_data['conv2'][0],name='conv2_w',trainable=variable_trable[2]), \\\n",
    "        tf.Variable(net_data['conv2'][1],name='conv2_b',trainable=variable_trable[2])\n",
    "        conv2_=conv(maxpool1_, CONV2_W, CONV2_b, c_o=256, s_h=1, s_w=1, padding=\"SAME\", group=2)#27*27*256\n",
    "        relu2_=tf.nn.relu(conv2_)\n",
    "        norm2=lrn(relu2_)\n",
    "        maxpool2_=maxpool(norm2)\n",
    "        \n",
    "    #layer_3 conv3-relu\n",
    "    with tf.name_scope('layer_3'):\n",
    "        CONV3_W,CONV3_b=tf.Variable(net_data['conv3'][0],name='conv3_w',trainable=variable_trable[3]),\\\n",
    "        tf.Variable(net_data['conv3'][1],name='conv3_b',trainable=variable_trable[3])\n",
    "        conv3_=conv(maxpool2_, CONV3_W, CONV3_b, c_o=384, s_h=1, s_w=1, padding=\"SAME\", group=1)#13*13*384\n",
    "        relu3_=tf.nn.relu(conv3_)\n",
    "        \n",
    "    #layer_4 conv4-relu\n",
    "    with tf.name_scope('layer_4'):\n",
    "        CONV4_W,CONV4_b=tf.Variable(net_data['conv4'][0],name='conv4_w',trainable=variable_trable[4]), \\\n",
    "        tf.Variable(net_data['conv4'][1],name='conv4_b',trainable=variable_trable[4])\n",
    "        conv4_=conv(relu3_, CONV4_W, CONV4_b, c_o=384, s_h=1, s_w=1, padding=\"SAME\", group=2)#13*13*384\n",
    "        relu4_=tf.nn.relu(conv4_)\n",
    "    \n",
    "    #layer_5 conv5-relu-maxpool\n",
    "    with tf.name_scope('layer_5'):\n",
    "        CONV5_W,CONV5_b=tf.Variable(net_data['conv5'][0],name='conv5_w',trainable=variable_trable[5]), \\\n",
    "        tf.Variable(net_data['conv5'][1],name='conv5_b',trainable=variable_trable[5])\n",
    "        conv5_=conv(relu4_, CONV5_W, CONV5_b, c_o=256, s_h=1, s_w=1, padding=\"SAME\", group=2)\n",
    "        relu5_=tf.nn.relu(conv5_)\n",
    "        maxpool5_=maxpool(relu5_)\n",
    "        \n",
    "    with tf.name_scope('layer_6'):\n",
    "        floatten_input=tf.reshape(maxpool5_,[-1,9216])#N*9216\n",
    "        floatten_input=tf.nn.dropout(x=floatten_input,keep_prob=keep_prob)\n",
    "        fc6_w,fc6_b=tf.Variable(net_data['fc6'][0],name='fc6_w',trainable=variable_trable[6]), \\\n",
    "        tf.Variable(net_data['fc6'][1],name='fc7_b',trainable=variable_trable[6])\n",
    "        fc6_=tf.matmul(floatten_input,fc6_w)+fc6_b\n",
    "        relu6_=tf.nn.relu(fc6_)#N*4096\n",
    "    with tf.name_scope('layer_7'):\n",
    "        relu6_=tf.nn.dropout(x=relu6_,keep_prob=keep_prob)\n",
    "        fc7_w,fc7_b=tf.Variable(net_data['fc7'][0],name='fc7_w',trainable=variable_trable[7]),\\\n",
    "        tf.Variable(net_data['fc7'][1],name='fc7_b',trainable=variable_trable[7])\n",
    "        fc7_=tf.matmul(relu6_,fc7_w)+fc7_b\n",
    "        relu7_=tf.nn.relu(fc7_)#N*4096\n",
    "    with tf.name_scope('layer_8'):\n",
    "#         fc8_w,fc8_b=tf.Variable(net_data['fc8'][0],name='fc8_w',trainable=variable_trable[8]), \\\n",
    "#         tf.Variable(net_data['fc8'][1],name='fc8_b',trainable=variable_trable[8])\n",
    "        relu7_=tf.nn.dropout(x=relu7_,keep_prob=keep_prob)\n",
    "        #最后一层fc层必须要重新训练\n",
    "        fc8_w=tf.Variable(tf.truncated_normal(shape=[4096,5],stddev=0.01),dtype=tf.float32,name='fc8_w',\\\n",
    "                          trainable=variable_trable[8])\n",
    "        fc8_b=tf.Variable(tf.zeros(shape=[5]),dtype=tf.float32,name='fc8_b',trainable=variable_trable[8])\n",
    "        fc8_=tf.matmul(relu7_,fc8_w)+fc8_b#N*1000\n",
    "    return fc8_\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg_pen=tf.reduce_sum([tf.reduce_sum(tf.square(i)) for i in tf.trainable_variables()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "netdata=load_model_weight_and_biases()\n",
    "with tf.name_scope('input'):\n",
    "    X=tf.placeholder(dtype=tf.float32,shape=[None,227,227,3])\n",
    "    Y=tf.placeholder(dtype=tf.float32,shape=[None,5])\n",
    "    KEEP_PROB=tf.placeholder(dtype=tf.float32)\n",
    "    LEARNRATE=tf.placeholder(dtype=tf.float32)\n",
    "with tf.name_scope('predict'):\n",
    "    y_pre=alexnet(X,netdata,KEEP_PROB)\n",
    "    prob=tf.nn.softmax(y_pre)\n",
    "#loss\n",
    "with tf.name_scope('loss'):\n",
    "    loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pre,labels=Y))\n",
    "    loss+=1e-4*reg_pen\n",
    "with tf.name_scope('trainer'):\n",
    "    trainer=tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
    "with tf.name_scope('accuracy'):\n",
    "    acc_c=tf.equal(tf.arg_max(y_pre,1),tf.arg_max(Y,1))\n",
    "    accuracy=tf.reduce_mean(tf.cast(x=acc_c,dtype=tf.float32))\n",
    "sess=tf.InteractiveSession()\n",
    "#writer=tf.summary.FileWriter('./mylog',sess.graph)\n",
    "init=tf.global_variables_initializer()\n",
    "writer=tf.summary.FileWriter(r'D:\\Data warehouse\\temp_dump\\mylog\\train_fc7tofc8')\n",
    "writer_=tf.summary.FileWriter(r'D:\\Data warehouse\\temp_dump\\mylog\\test_fc7tofc8')\n",
    "tf.summary.scalar('loss',loss)\n",
    "tf.summary.scalar('accuracy',accuracy)\n",
    "merge=tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "fp=open(r'D:\\Data warehouse\\5 flower\\flower_photos\\flower.pkl','rb')\n",
    "flower_dict=pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TR_IMG,TE_IMG=flower_dict['train']['image'].astype(np.float32),flower_dict['test']['image'].astype(np.float32)\n",
    "TR_LAB,TE_LAB=flower_dict['train']['label'].astype(np.float32),flower_dict['test']['label'].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del flower_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0,loss:2.0476887226104736,train accuracy:0.28125\n",
      "--epoch:0,loss:2.6251590251922607,test accuracy:0.6953125\n",
      "epoch:1,loss:2.828031539916992,train accuracy:0.6796875\n",
      "epoch:2,loss:2.522392749786377,train accuracy:0.703125\n",
      "epoch:3,loss:1.5997705459594727,train accuracy:0.765625\n",
      "epoch:4,loss:2.030029058456421,train accuracy:0.703125\n",
      "epoch:5,loss:1.185170292854309,train accuracy:0.8203125\n",
      "--epoch:5,loss:0.8891972303390503,test accuracy:0.75\n",
      "epoch:6,loss:1.7880452871322632,train accuracy:0.7421875\n",
      "epoch:7,loss:0.7682040929794312,train accuracy:0.828125\n",
      "epoch:8,loss:1.1914187669754028,train accuracy:0.78125\n",
      "epoch:9,loss:1.07383131980896,train accuracy:0.8046875\n",
      "epoch:10,loss:0.8696883916854858,train accuracy:0.828125\n",
      "--epoch:10,loss:0.9965732097625732,test accuracy:0.7734375\n",
      "epoch:11,loss:0.8289076089859009,train accuracy:0.828125\n",
      "epoch:12,loss:1.2061749696731567,train accuracy:0.7734375\n",
      "epoch:13,loss:0.7513988018035889,train accuracy:0.8359375\n",
      "epoch:14,loss:0.9110493659973145,train accuracy:0.8203125\n",
      "epoch:15,loss:1.1072345972061157,train accuracy:0.7578125\n",
      "epoch 15,learning rate:0.00099\n",
      "--epoch:15,loss:0.7181766033172607,test accuracy:0.8046875\n",
      "epoch:16,loss:0.7016855478286743,train accuracy:0.8125\n",
      "epoch:17,loss:0.7158257961273193,train accuracy:0.8515625\n",
      "epoch:18,loss:0.6690096855163574,train accuracy:0.84375\n",
      "epoch:19,loss:1.354217290878296,train accuracy:0.78125\n",
      "epoch:20,loss:0.6046574711799622,train accuracy:0.8515625\n",
      "epoch 20,learning rate:0.0009801\n",
      "--epoch:20,loss:0.4810420572757721,test accuracy:0.859375\n",
      "epoch:21,loss:0.6025173664093018,train accuracy:0.828125\n",
      "epoch:22,loss:0.773460865020752,train accuracy:0.8125\n",
      "epoch:23,loss:0.5099765062332153,train accuracy:0.8671875\n",
      "epoch:24,loss:1.0349116325378418,train accuracy:0.828125\n",
      "epoch:25,loss:0.3716548681259155,train accuracy:0.890625\n",
      "epoch 25,learning rate:0.000970299\n",
      "--epoch:25,loss:0.8119674921035767,test accuracy:0.828125\n",
      "epoch:26,loss:0.7274104356765747,train accuracy:0.875\n",
      "epoch:27,loss:0.9757581353187561,train accuracy:0.84375\n",
      "epoch:28,loss:0.3638605773448944,train accuracy:0.890625\n",
      "epoch:29,loss:0.7922890186309814,train accuracy:0.875\n",
      "epoch:30,loss:0.685406506061554,train accuracy:0.8515625\n",
      "epoch 30,learning rate:0.0009605960099999999\n",
      "--epoch:30,loss:0.6624050736427307,test accuracy:0.8203125\n",
      "epoch:31,loss:0.3754498362541199,train accuracy:0.9140625\n",
      "epoch:32,loss:0.5069177150726318,train accuracy:0.8359375\n",
      "epoch:33,loss:0.4057711064815521,train accuracy:0.8984375\n",
      "epoch:34,loss:0.3038140535354614,train accuracy:0.921875\n",
      "epoch:35,loss:0.4362259805202484,train accuracy:0.875\n",
      "epoch 35,learning rate:0.0009509900498999999\n",
      "--epoch:35,loss:0.3883684277534485,test accuracy:0.8828125\n",
      "epoch:36,loss:0.8107762336730957,train accuracy:0.8203125\n",
      "epoch:37,loss:0.5755293369293213,train accuracy:0.875\n",
      "epoch:38,loss:0.38948675990104675,train accuracy:0.9140625\n",
      "epoch:39,loss:0.6037766337394714,train accuracy:0.8515625\n",
      "epoch:40,loss:0.8765637874603271,train accuracy:0.8359375\n",
      "--epoch:40,loss:0.9604049921035767,test accuracy:0.7890625\n",
      "epoch:41,loss:0.338776171207428,train accuracy:0.921875\n",
      "epoch:42,loss:1.0627729892730713,train accuracy:0.859375\n",
      "epoch:43,loss:0.41878288984298706,train accuracy:0.8671875\n",
      "epoch:44,loss:0.942406952381134,train accuracy:0.8046875\n",
      "epoch:45,loss:0.3919774889945984,train accuracy:0.90625\n",
      "epoch 45,learning rate:0.0009414801494009999\n",
      "--epoch:45,loss:1.0477123260498047,test accuracy:0.8046875\n",
      "epoch:46,loss:0.9759281277656555,train accuracy:0.84375\n",
      "epoch:47,loss:0.5036501884460449,train accuracy:0.890625\n",
      "epoch:48,loss:0.49976646900177,train accuracy:0.875\n",
      "epoch:49,loss:0.7129235863685608,train accuracy:0.84375\n",
      "epoch:50,loss:0.2935488820075989,train accuracy:0.90625\n",
      "epoch 50,learning rate:0.0009320653479069899\n",
      "--epoch:50,loss:0.5798596739768982,test accuracy:0.859375\n",
      "epoch:51,loss:0.3637640178203583,train accuracy:0.90625\n",
      "epoch:52,loss:0.4887380599975586,train accuracy:0.8984375\n",
      "epoch:53,loss:0.2952369153499603,train accuracy:0.8984375\n",
      "epoch:54,loss:0.38647598028182983,train accuracy:0.9375\n",
      "epoch:55,loss:0.44730648398399353,train accuracy:0.921875\n",
      "--epoch:55,loss:1.0280007123947144,test accuracy:0.78125\n",
      "epoch:56,loss:0.7849968075752258,train accuracy:0.875\n",
      "epoch:57,loss:0.5064419507980347,train accuracy:0.8984375\n",
      "epoch:58,loss:0.4012802839279175,train accuracy:0.9140625\n",
      "epoch:59,loss:0.38360482454299927,train accuracy:0.9453125\n",
      "epoch:60,loss:0.3239760100841522,train accuracy:0.90625\n",
      "epoch 60,learning rate:0.00092274469442792\n",
      "--epoch:60,loss:0.8441681265830994,test accuracy:0.84375\n",
      "epoch:61,loss:0.666824460029602,train accuracy:0.9140625\n",
      "epoch:62,loss:0.37577369809150696,train accuracy:0.9140625\n",
      "epoch:63,loss:0.5391458868980408,train accuracy:0.8671875\n",
      "epoch:64,loss:0.41095227003097534,train accuracy:0.8984375\n",
      "epoch:65,loss:0.4842223823070526,train accuracy:0.890625\n",
      "epoch 65,learning rate:0.0009135172474836408\n",
      "--epoch:65,loss:0.6106021404266357,test accuracy:0.84375\n",
      "epoch:66,loss:0.4209812581539154,train accuracy:0.890625\n",
      "epoch:67,loss:0.32311445474624634,train accuracy:0.9296875\n",
      "epoch:68,loss:0.6779930591583252,train accuracy:0.890625\n",
      "epoch:69,loss:0.32506969571113586,train accuracy:0.9375\n",
      "epoch:70,loss:0.6232444047927856,train accuracy:0.90625\n",
      "--epoch:70,loss:0.9460756182670593,test accuracy:0.78125\n",
      "epoch:71,loss:0.25581732392311096,train accuracy:0.953125\n",
      "epoch:72,loss:0.23782093822956085,train accuracy:0.9375\n",
      "epoch:73,loss:0.7284358739852905,train accuracy:0.859375\n",
      "epoch:74,loss:0.3230903744697571,train accuracy:0.8984375\n",
      "epoch:75,loss:0.9918379187583923,train accuracy:0.8515625\n",
      "epoch 75,learning rate:0.0009043820750088043\n",
      "--epoch:75,loss:0.6739585399627686,test accuracy:0.859375\n",
      "epoch:76,loss:0.38616371154785156,train accuracy:0.90625\n",
      "epoch:77,loss:0.32532715797424316,train accuracy:0.9375\n",
      "epoch:78,loss:0.2744072675704956,train accuracy:0.9453125\n",
      "epoch:79,loss:0.5083683729171753,train accuracy:0.8984375\n",
      "epoch:80,loss:0.1657426655292511,train accuracy:0.9453125\n",
      "epoch 80,learning rate:0.0008953382542587163\n",
      "--epoch:80,loss:1.013024091720581,test accuracy:0.8203125\n",
      "epoch:81,loss:0.13679243624210358,train accuracy:0.9609375\n",
      "epoch:82,loss:0.6907915472984314,train accuracy:0.890625\n",
      "epoch:83,loss:0.19697877764701843,train accuracy:0.9453125\n",
      "epoch:84,loss:0.47144412994384766,train accuracy:0.8984375\n",
      "epoch:85,loss:0.4594341516494751,train accuracy:0.921875\n",
      "--epoch:85,loss:1.038717269897461,test accuracy:0.796875\n",
      "epoch:86,loss:0.3059682846069336,train accuracy:0.9453125\n",
      "epoch:87,loss:0.2571154832839966,train accuracy:0.9375\n",
      "epoch:88,loss:0.6833088994026184,train accuracy:0.8984375\n",
      "epoch:89,loss:0.15736103057861328,train accuracy:0.9375\n",
      "epoch:90,loss:0.08921901881694794,train accuracy:0.9609375\n",
      "epoch 90,learning rate:0.0008863848717161291\n",
      "--epoch:90,loss:0.7440528869628906,test accuracy:0.8828125\n",
      "epoch:91,loss:0.5195952653884888,train accuracy:0.8984375\n",
      "epoch:92,loss:0.19400134682655334,train accuracy:0.9765625\n",
      "epoch:93,loss:0.2940833866596222,train accuracy:0.921875\n",
      "epoch:94,loss:0.4193257689476013,train accuracy:0.9375\n",
      "epoch:95,loss:0.461290180683136,train accuracy:0.890625\n",
      "epoch 95,learning rate:0.0008775210229989678\n",
      "--epoch:95,loss:0.6448429822921753,test accuracy:0.828125\n",
      "epoch:96,loss:0.49059706926345825,train accuracy:0.8828125\n",
      "epoch:97,loss:0.26845964789390564,train accuracy:0.9140625\n",
      "epoch:98,loss:0.33537009358406067,train accuracy:0.9296875\n",
      "epoch:99,loss:0.24887853860855103,train accuracy:0.9296875\n",
      "epoch:100,loss:0.24867986142635345,train accuracy:0.9375\n",
      "epoch 100,learning rate:0.0008687458127689781\n",
      "--epoch:100,loss:0.817407488822937,test accuracy:0.84375\n",
      "epoch:101,loss:0.12716053426265717,train accuracy:0.953125\n",
      "epoch:102,loss:0.5606560707092285,train accuracy:0.953125\n",
      "epoch:103,loss:0.11418664455413818,train accuracy:0.96875\n",
      "epoch:104,loss:0.37803134322166443,train accuracy:0.90625\n",
      "epoch:105,loss:0.4327843189239502,train accuracy:0.9140625\n",
      "epoch 105,learning rate:0.0008600583546412883\n",
      "--epoch:105,loss:1.0205256938934326,test accuracy:0.8046875\n",
      "epoch:106,loss:0.19603846967220306,train accuracy:0.9375\n",
      "epoch:107,loss:0.5124273300170898,train accuracy:0.90625\n",
      "epoch:108,loss:0.2728203535079956,train accuracy:0.921875\n",
      "epoch:109,loss:0.47884896397590637,train accuracy:0.8828125\n",
      "epoch:110,loss:0.35324475169181824,train accuracy:0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110,learning rate:0.0008514577710948754\n",
      "--epoch:110,loss:1.0242254734039307,test accuracy:0.859375\n",
      "epoch:111,loss:0.38196420669555664,train accuracy:0.9296875\n",
      "epoch:112,loss:0.15797176957130432,train accuracy:0.9609375\n",
      "epoch:113,loss:0.1037834882736206,train accuracy:0.9765625\n",
      "epoch:114,loss:0.2536734938621521,train accuracy:0.921875\n",
      "epoch:115,loss:0.2950151562690735,train accuracy:0.9375\n",
      "epoch 115,learning rate:0.0008429431933839266\n",
      "--epoch:115,loss:0.7152047753334045,test accuracy:0.8671875\n",
      "epoch:116,loss:0.22080688178539276,train accuracy:0.953125\n",
      "epoch:117,loss:0.6305350065231323,train accuracy:0.9140625\n",
      "epoch:118,loss:0.30261728167533875,train accuracy:0.921875\n",
      "epoch:119,loss:0.3490713834762573,train accuracy:0.9296875\n",
      "epoch:120,loss:0.29002442955970764,train accuracy:0.9375\n",
      "epoch 120,learning rate:0.0008345137614500873\n",
      "--epoch:120,loss:0.9771071076393127,test accuracy:0.859375\n",
      "epoch:121,loss:0.238882377743721,train accuracy:0.9453125\n",
      "epoch:122,loss:0.3811500370502472,train accuracy:0.9453125\n",
      "epoch:123,loss:0.3759705424308777,train accuracy:0.9140625\n",
      "epoch:124,loss:0.36926722526550293,train accuracy:0.9140625\n",
      "epoch:125,loss:0.4289941191673279,train accuracy:0.9296875\n",
      "epoch 125,learning rate:0.0008261686238355864\n",
      "--epoch:125,loss:0.718672513961792,test accuracy:0.90625\n",
      "epoch:126,loss:0.09606784582138062,train accuracy:0.96875\n",
      "epoch:127,loss:0.3064233064651489,train accuracy:0.9453125\n",
      "epoch:128,loss:0.07979905605316162,train accuracy:0.96875\n",
      "epoch:129,loss:0.2637864947319031,train accuracy:0.9296875\n",
      "epoch:130,loss:0.1731385588645935,train accuracy:0.9453125\n",
      "epoch 130,learning rate:0.0008179069375972306\n",
      "--epoch:130,loss:1.3668550252914429,test accuracy:0.8125\n",
      "epoch:131,loss:0.1646658033132553,train accuracy:0.953125\n",
      "epoch:132,loss:0.21561071276664734,train accuracy:0.953125\n",
      "epoch:133,loss:0.4172389805316925,train accuracy:0.90625\n",
      "epoch:134,loss:0.3764389455318451,train accuracy:0.9453125\n",
      "epoch:135,loss:0.3931000530719757,train accuracy:0.9453125\n",
      "epoch 135,learning rate:0.0008097278682212583\n",
      "--epoch:135,loss:0.951906144618988,test accuracy:0.8671875\n",
      "epoch:136,loss:0.48922863602638245,train accuracy:0.921875\n",
      "epoch:137,loss:0.47096192836761475,train accuracy:0.8984375\n",
      "epoch:138,loss:0.14366084337234497,train accuracy:0.9609375\n",
      "epoch:139,loss:0.11077358573675156,train accuracy:0.96875\n",
      "epoch:140,loss:0.2443963587284088,train accuracy:0.9609375\n",
      "--epoch:140,loss:1.535988688468933,test accuracy:0.7890625\n",
      "epoch:141,loss:0.3669194281101227,train accuracy:0.9296875\n",
      "epoch:142,loss:0.19545938074588776,train accuracy:0.9375\n",
      "epoch:143,loss:0.25542953610420227,train accuracy:0.9375\n",
      "epoch:144,loss:0.9849560260772705,train accuracy:0.8984375\n",
      "epoch:145,loss:0.44272682070732117,train accuracy:0.9765625\n",
      "epoch 145,learning rate:0.0008016305895390457\n",
      "--epoch:145,loss:1.3014497756958008,test accuracy:0.8359375\n",
      "epoch:146,loss:0.14702993631362915,train accuracy:0.9609375\n",
      "epoch:147,loss:0.24908171594142914,train accuracy:0.9296875\n",
      "epoch:148,loss:0.2726845443248749,train accuracy:0.9375\n",
      "epoch:149,loss:0.2749677300453186,train accuracy:0.953125\n",
      "epoch:150,loss:0.15659287571907043,train accuracy:0.953125\n",
      "epoch 150,learning rate:0.0007936142836436553\n",
      "--epoch:150,loss:1.080259919166565,test accuracy:0.8203125\n",
      "epoch:151,loss:0.1287076324224472,train accuracy:0.9609375\n",
      "epoch:152,loss:0.3102790415287018,train accuracy:0.9375\n",
      "epoch:153,loss:0.2718845009803772,train accuracy:0.9296875\n",
      "epoch:154,loss:0.1470375657081604,train accuracy:0.9375\n",
      "epoch:155,loss:0.10267339646816254,train accuracy:0.984375\n",
      "--epoch:155,loss:1.7392710447311401,test accuracy:0.765625\n",
      "epoch:156,loss:0.1485416740179062,train accuracy:0.9765625\n",
      "epoch:157,loss:0.49883508682250977,train accuracy:0.9453125\n",
      "epoch:158,loss:0.28627151250839233,train accuracy:0.9296875\n",
      "epoch:159,loss:0.1907072812318802,train accuracy:0.96875\n",
      "epoch:160,loss:0.2556786835193634,train accuracy:0.9609375\n",
      "epoch 160,learning rate:0.0007856781408072188\n",
      "--epoch:160,loss:0.6306031942367554,test accuracy:0.8515625\n",
      "epoch:161,loss:0.45762932300567627,train accuracy:0.9296875\n",
      "epoch:162,loss:0.3919863998889923,train accuracy:0.9453125\n",
      "epoch:163,loss:0.08695988357067108,train accuracy:0.9765625\n",
      "epoch:164,loss:0.22715704143047333,train accuracy:0.953125\n",
      "epoch:165,loss:0.3598368167877197,train accuracy:0.953125\n",
      "epoch 165,learning rate:0.0007778213593991466\n",
      "--epoch:165,loss:0.9383060336112976,test accuracy:0.84375\n",
      "epoch:166,loss:0.05821578949689865,train accuracy:0.984375\n",
      "epoch:167,loss:0.18609821796417236,train accuracy:0.9609375\n",
      "epoch:168,loss:0.25509709119796753,train accuracy:0.9765625\n",
      "epoch:169,loss:0.36693164706230164,train accuracy:0.9453125\n",
      "epoch:170,loss:0.29551243782043457,train accuracy:0.90625\n",
      "epoch 170,learning rate:0.000770043145805155\n",
      "--epoch:170,loss:0.8912325501441956,test accuracy:0.8515625\n",
      "epoch:171,loss:0.249187171459198,train accuracy:0.9609375\n",
      "epoch:172,loss:0.2729703485965729,train accuracy:0.9609375\n",
      "epoch:173,loss:0.2653231620788574,train accuracy:0.9453125\n",
      "epoch:174,loss:0.259901762008667,train accuracy:0.953125\n",
      "epoch:175,loss:0.1107192412018776,train accuracy:0.9609375\n",
      "epoch 175,learning rate:0.0007623427143471034\n",
      "--epoch:175,loss:1.5853805541992188,test accuracy:0.8515625\n",
      "epoch:176,loss:0.39612653851509094,train accuracy:0.9375\n",
      "epoch:177,loss:0.39396369457244873,train accuracy:0.9453125\n",
      "epoch:178,loss:0.3783724009990692,train accuracy:0.90625\n",
      "epoch:179,loss:0.332979291677475,train accuracy:0.9453125\n",
      "epoch:180,loss:0.18088290095329285,train accuracy:0.9609375\n",
      "epoch 180,learning rate:0.0007547192872036325\n",
      "--epoch:180,loss:1.841996431350708,test accuracy:0.828125\n",
      "epoch:181,loss:0.3209156095981598,train accuracy:0.9453125\n",
      "epoch:182,loss:0.24326260387897491,train accuracy:0.953125\n",
      "epoch:183,loss:0.2765018343925476,train accuracy:0.9453125\n",
      "epoch:184,loss:0.29100626707077026,train accuracy:0.9453125\n",
      "epoch:185,loss:0.6135503053665161,train accuracy:0.90625\n",
      "epoch 185,learning rate:0.0007471720943315961\n",
      "--epoch:185,loss:1.0768471956253052,test accuracy:0.84375\n",
      "epoch:186,loss:0.06596873700618744,train accuracy:0.9765625\n",
      "epoch:187,loss:0.08204265683889389,train accuracy:0.9765625\n",
      "epoch:188,loss:0.19095703959465027,train accuracy:0.9609375\n",
      "epoch:189,loss:0.27380311489105225,train accuracy:0.9609375\n",
      "epoch:190,loss:0.032501496374607086,train accuracy:0.984375\n",
      "epoch 190,learning rate:0.0007397003733882801\n",
      "--epoch:190,loss:0.7173224687576294,test accuracy:0.921875\n",
      "epoch:191,loss:0.32857847213745117,train accuracy:0.9453125\n",
      "epoch:192,loss:0.1319960206747055,train accuracy:0.96875\n",
      "epoch:193,loss:0.3562009632587433,train accuracy:0.9765625\n",
      "epoch:194,loss:0.2442181259393692,train accuracy:0.953125\n",
      "epoch:195,loss:0.058622099459171295,train accuracy:0.96875\n",
      "epoch 195,learning rate:0.0007323033696543973\n",
      "--epoch:195,loss:1.0445809364318848,test accuracy:0.8515625\n",
      "epoch:196,loss:0.44563132524490356,train accuracy:0.953125\n",
      "epoch:197,loss:0.2940448224544525,train accuracy:0.9609375\n",
      "epoch:198,loss:0.2917582094669342,train accuracy:0.9375\n",
      "epoch:199,loss:0.012369096279144287,train accuracy:0.9921875\n",
      "epoch:200,loss:0.1422426849603653,train accuracy:0.9765625\n",
      "epoch 200,learning rate:0.0007249803359578533\n",
      "--epoch:200,loss:1.2139142751693726,test accuracy:0.8515625\n",
      "epoch:201,loss:0.09784109145402908,train accuracy:0.96875\n",
      "epoch:202,loss:0.16502077877521515,train accuracy:0.9375\n",
      "epoch:203,loss:0.2653137743473053,train accuracy:0.953125\n",
      "epoch:204,loss:0.041162826120853424,train accuracy:0.984375\n",
      "epoch:205,loss:0.2300293743610382,train accuracy:0.9609375\n",
      "epoch 205,learning rate:0.0007177305325982747\n",
      "--epoch:205,loss:1.2187292575836182,test accuracy:0.828125\n",
      "epoch:206,loss:0.11571449041366577,train accuracy:0.96875\n",
      "epoch:207,loss:0.41993996500968933,train accuracy:0.9375\n",
      "epoch:208,loss:0.025977380573749542,train accuracy:0.9921875\n",
      "epoch:209,loss:0.1644582748413086,train accuracy:0.9453125\n",
      "epoch:210,loss:0.10601820051670074,train accuracy:0.9609375\n",
      "--epoch:210,loss:1.8921902179718018,test accuracy:0.7734375\n",
      "epoch:211,loss:0.051500361412763596,train accuracy:0.984375\n",
      "epoch:212,loss:0.07166911661624908,train accuracy:0.96875\n",
      "epoch:213,loss:0.0006431204383261502,train accuracy:1.0\n",
      "epoch:214,loss:0.9536452293395996,train accuracy:0.9375\n",
      "epoch:215,loss:0.19224873185157776,train accuracy:0.9765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 215,learning rate:0.000710553227272292\n",
      "--epoch:215,loss:1.1497387886047363,test accuracy:0.8359375\n",
      "epoch:216,loss:0.06985322386026382,train accuracy:0.9765625\n",
      "epoch:217,loss:0.17936383187770844,train accuracy:0.9765625\n",
      "epoch:218,loss:0.11962266266345978,train accuracy:0.96875\n",
      "epoch:219,loss:0.15759089589118958,train accuracy:0.9765625\n",
      "epoch:220,loss:0.5550674200057983,train accuracy:0.9453125\n",
      "epoch 220,learning rate:0.000703447694999569\n",
      "--epoch:220,loss:0.6690495014190674,test accuracy:0.8515625\n",
      "epoch:221,loss:0.1216120645403862,train accuracy:0.96875\n",
      "epoch:222,loss:0.14704912900924683,train accuracy:0.9765625\n",
      "epoch:223,loss:0.08323919773101807,train accuracy:0.9765625\n",
      "epoch:224,loss:0.06535838544368744,train accuracy:0.984375\n",
      "epoch:225,loss:0.1736755222082138,train accuracy:0.9609375\n",
      "epoch 225,learning rate:0.0006964132180495733\n",
      "--epoch:225,loss:1.3014391660690308,test accuracy:0.828125\n",
      "epoch:226,loss:0.149857759475708,train accuracy:0.9765625\n",
      "epoch:227,loss:0.5378906726837158,train accuracy:0.9453125\n",
      "epoch:228,loss:0.03914649784564972,train accuracy:0.9921875\n",
      "epoch:229,loss:0.18222717940807343,train accuracy:0.9609375\n",
      "epoch:230,loss:0.42193469405174255,train accuracy:0.9375\n",
      "epoch 230,learning rate:0.0006894490858690775\n",
      "--epoch:230,loss:1.226818323135376,test accuracy:0.875\n",
      "epoch:231,loss:0.18533489108085632,train accuracy:0.9453125\n",
      "epoch:232,loss:0.514167070388794,train accuracy:0.9765625\n",
      "epoch:233,loss:0.4428825378417969,train accuracy:0.9375\n",
      "epoch:234,loss:0.40491247177124023,train accuracy:0.9375\n",
      "epoch:235,loss:0.5538312196731567,train accuracy:0.921875\n",
      "epoch 235,learning rate:0.0006825545950103868\n",
      "--epoch:235,loss:1.1648253202438354,test accuracy:0.8359375\n",
      "epoch:236,loss:0.07987631857395172,train accuracy:0.984375\n",
      "epoch:237,loss:0.18743331730365753,train accuracy:0.96875\n",
      "epoch:238,loss:0.1179652214050293,train accuracy:0.984375\n",
      "epoch:239,loss:0.027438724413514137,train accuracy:0.9921875\n",
      "epoch:240,loss:0.028632665053009987,train accuracy:0.9921875\n",
      "epoch 240,learning rate:0.000675729049060283\n",
      "--epoch:240,loss:0.9168046712875366,test accuracy:0.875\n",
      "epoch:241,loss:0.08260330557823181,train accuracy:0.9765625\n",
      "epoch:242,loss:0.26993587613105774,train accuracy:0.953125\n",
      "epoch:243,loss:0.05845437943935394,train accuracy:0.96875\n",
      "epoch:244,loss:0.07374858856201172,train accuracy:0.9765625\n",
      "epoch:245,loss:0.2632880210876465,train accuracy:0.96875\n",
      "epoch 245,learning rate:0.0006689717585696801\n",
      "--epoch:245,loss:1.6035778522491455,test accuracy:0.828125\n",
      "epoch:246,loss:0.2425754815340042,train accuracy:0.953125\n",
      "epoch:247,loss:0.0020571029745042324,train accuracy:1.0\n",
      "epoch:248,loss:0.12799321115016937,train accuracy:0.984375\n",
      "epoch:249,loss:0.2954683005809784,train accuracy:0.96875\n",
      "epoch:250,loss:0.33936452865600586,train accuracy:0.9765625\n",
      "epoch 250,learning rate:0.0006622820409839833\n",
      "--epoch:250,loss:1.2173840999603271,test accuracy:0.8671875\n",
      "epoch:251,loss:0.04375765100121498,train accuracy:0.9765625\n",
      "epoch:252,loss:0.6051040887832642,train accuracy:0.9296875\n",
      "epoch:253,loss:0.15395812690258026,train accuracy:0.9765625\n",
      "epoch:254,loss:0.08423233032226562,train accuracy:0.9921875\n",
      "epoch:255,loss:0.3347510099411011,train accuracy:0.953125\n",
      "epoch 255,learning rate:0.0006556592205741434\n",
      "--epoch:255,loss:0.8227294683456421,test accuracy:0.8828125\n",
      "epoch:256,loss:0.027087152004241943,train accuracy:0.984375\n",
      "epoch:257,loss:0.1697573959827423,train accuracy:0.96875\n",
      "epoch:258,loss:0.06581483781337738,train accuracy:0.9765625\n",
      "epoch:259,loss:0.034631770104169846,train accuracy:0.9921875\n",
      "epoch:260,loss:0.14749814569950104,train accuracy:0.9765625\n",
      "epoch 260,learning rate:0.0006491026283684019\n",
      "--epoch:260,loss:1.2021293640136719,test accuracy:0.8671875\n",
      "epoch:261,loss:0.18024063110351562,train accuracy:0.96875\n",
      "epoch:262,loss:0.13700221478939056,train accuracy:0.984375\n",
      "epoch:263,loss:0.048710789531469345,train accuracy:0.9921875\n",
      "epoch:264,loss:0.32243412733078003,train accuracy:0.96875\n",
      "epoch:265,loss:0.08925757557153702,train accuracy:0.984375\n",
      "epoch 265,learning rate:0.0006426116020847179\n",
      "--epoch:265,loss:1.2073948383331299,test accuracy:0.8671875\n",
      "epoch:266,loss:0.21954740583896637,train accuracy:0.984375\n",
      "epoch:267,loss:0.08822320401668549,train accuracy:0.984375\n",
      "epoch:268,loss:0.16712073981761932,train accuracy:0.96875\n",
      "epoch:269,loss:0.3633548617362976,train accuracy:0.953125\n",
      "epoch:270,loss:0.2756587564945221,train accuracy:0.9609375\n",
      "epoch 270,learning rate:0.0006361854860638707\n",
      "--epoch:270,loss:0.787239670753479,test accuracy:0.890625\n",
      "epoch:271,loss:0.38328060507774353,train accuracy:0.96875\n",
      "epoch:272,loss:0.17500290274620056,train accuracy:0.9609375\n",
      "epoch:273,loss:0.1555604338645935,train accuracy:0.953125\n",
      "epoch:274,loss:0.17431265115737915,train accuracy:0.9765625\n",
      "epoch:275,loss:0.10965865850448608,train accuracy:0.984375\n",
      "epoch 275,learning rate:0.000629823631203232\n",
      "--epoch:275,loss:1.5710123777389526,test accuracy:0.8046875\n",
      "epoch:276,loss:0.17151272296905518,train accuracy:0.96875\n",
      "epoch:277,loss:0.29095685482025146,train accuracy:0.9609375\n",
      "epoch:278,loss:0.07777084410190582,train accuracy:0.9921875\n",
      "epoch:279,loss:0.19890721142292023,train accuracy:0.96875\n",
      "epoch:280,loss:0.09317232668399811,train accuracy:0.984375\n",
      "epoch 280,learning rate:0.0006235253948911997\n",
      "--epoch:280,loss:0.914093017578125,test accuracy:0.875\n",
      "epoch:281,loss:0.14701059460639954,train accuracy:0.96875\n",
      "epoch:282,loss:0.0795476883649826,train accuracy:0.9765625\n",
      "epoch:283,loss:0.11520720273256302,train accuracy:0.96875\n",
      "epoch:284,loss:0.14981578290462494,train accuracy:0.96875\n",
      "epoch:285,loss:0.15283161401748657,train accuracy:0.9609375\n",
      "epoch 285,learning rate:0.0006172901409422877\n",
      "--epoch:285,loss:1.8614869117736816,test accuracy:0.8203125\n",
      "epoch:286,loss:0.2234957069158554,train accuracy:0.96875\n",
      "epoch:287,loss:0.08242698013782501,train accuracy:0.9765625\n",
      "epoch:288,loss:0.2342706322669983,train accuracy:0.9375\n",
      "epoch:289,loss:0.2393663227558136,train accuracy:0.9609375\n",
      "epoch:290,loss:0.34124666452407837,train accuracy:0.96875\n",
      "epoch 290,learning rate:0.0006111172395328649\n",
      "--epoch:290,loss:1.4131314754486084,test accuracy:0.859375\n",
      "epoch:291,loss:0.2748226523399353,train accuracy:0.953125\n",
      "epoch:292,loss:0.15025396645069122,train accuracy:0.9609375\n",
      "epoch:293,loss:0.8041206002235413,train accuracy:0.9140625\n",
      "epoch:294,loss:0.23934587836265564,train accuracy:0.9765625\n",
      "epoch:295,loss:0.3409622609615326,train accuracy:0.9609375\n",
      "epoch 295,learning rate:0.0006050060671375363\n",
      "--epoch:295,loss:1.72963547706604,test accuracy:0.8125\n",
      "epoch:296,loss:0.30379679799079895,train accuracy:0.96875\n",
      "epoch:297,loss:0.19849500060081482,train accuracy:0.9609375\n",
      "epoch:298,loss:0.5999170541763306,train accuracy:0.9296875\n",
      "epoch:299,loss:0.18848620355129242,train accuracy:0.9609375\n",
      "epoch:300,loss:0.12251502275466919,train accuracy:0.9765625\n",
      "epoch 300,learning rate:0.0005989560064661609\n",
      "--epoch:300,loss:1.3617310523986816,test accuracy:0.8671875\n",
      "epoch:301,loss:0.5513876080513,train accuracy:0.9609375\n",
      "epoch:302,loss:0.16322572529315948,train accuracy:0.96875\n",
      "epoch:303,loss:0.12248352915048599,train accuracy:0.96875\n",
      "epoch:304,loss:0.13281533122062683,train accuracy:0.9765625\n",
      "epoch:305,loss:0.030230388045310974,train accuracy:0.984375\n",
      "epoch 305,learning rate:0.0005929664464014993\n",
      "--epoch:305,loss:0.8121305704116821,test accuracy:0.8984375\n",
      "epoch:306,loss:0.4299992620944977,train accuracy:0.9296875\n",
      "epoch:307,loss:0.33559903502464294,train accuracy:0.9609375\n",
      "epoch:308,loss:0.19959360361099243,train accuracy:0.984375\n",
      "epoch:309,loss:0.5456785559654236,train accuracy:0.953125\n",
      "epoch:310,loss:0.1873323619365692,train accuracy:0.96875\n",
      "epoch 310,learning rate:0.0005870367819374844\n",
      "--epoch:310,loss:0.8641291856765747,test accuracy:0.859375\n",
      "epoch:311,loss:0.13027629256248474,train accuracy:0.9765625\n",
      "epoch:312,loss:0.18783901631832123,train accuracy:0.9765625\n",
      "epoch:313,loss:0.17282111942768097,train accuracy:0.96875\n",
      "epoch:314,loss:0.2083471417427063,train accuracy:0.9765625\n",
      "epoch:315,loss:0.1615225225687027,train accuracy:0.984375\n",
      "--epoch:315,loss:1.8790074586868286,test accuracy:0.796875\n",
      "epoch:316,loss:0.0930127501487732,train accuracy:0.9921875\n",
      "epoch:317,loss:0.019512943923473358,train accuracy:0.9921875\n",
      "epoch:318,loss:0.20125143229961395,train accuracy:0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:319,loss:0.1452026665210724,train accuracy:0.984375\n",
      "epoch:320,loss:0.16614164412021637,train accuracy:0.9765625\n",
      "epoch 320,learning rate:0.0005811664141181095\n",
      "--epoch:320,loss:1.6058099269866943,test accuracy:0.8203125\n",
      "epoch:321,loss:0.013082778081297874,train accuracy:0.9921875\n",
      "epoch:322,loss:0.26342007517814636,train accuracy:0.9609375\n",
      "epoch:323,loss:0.011431097984313965,train accuracy:0.9921875\n",
      "epoch:324,loss:0.33977171778678894,train accuracy:0.9609375\n",
      "epoch:325,loss:0.5407716035842896,train accuracy:0.96875\n",
      "epoch 325,learning rate:0.0005753547499769285\n",
      "--epoch:325,loss:1.0707999467849731,test accuracy:0.8359375\n",
      "epoch:326,loss:0.004900130443274975,train accuracy:1.0\n",
      "epoch:327,loss:0.1463104635477066,train accuracy:0.9765625\n",
      "epoch:328,loss:0.6144694089889526,train accuracy:0.953125\n",
      "epoch:329,loss:0.1759500354528427,train accuracy:0.9609375\n",
      "epoch:330,loss:0.12241195142269135,train accuracy:0.96875\n",
      "epoch 330,learning rate:0.0005696012024771592\n",
      "--epoch:330,loss:1.3399865627288818,test accuracy:0.8359375\n",
      "epoch:331,loss:0.2043045163154602,train accuracy:0.9765625\n",
      "epoch:332,loss:0.04282977432012558,train accuracy:0.984375\n",
      "epoch:333,loss:0.600203275680542,train accuracy:0.984375\n",
      "epoch:334,loss:0.2719818651676178,train accuracy:0.9765625\n",
      "epoch:335,loss:0.250441312789917,train accuracy:0.9609375\n",
      "epoch 335,learning rate:0.0005639051904523875\n",
      "--epoch:335,loss:1.691686987876892,test accuracy:0.8359375\n",
      "epoch:336,loss:0.33411553502082825,train accuracy:0.9609375\n",
      "epoch:337,loss:0.33543819189071655,train accuracy:0.9296875\n",
      "epoch:338,loss:0.06893037259578705,train accuracy:0.9921875\n",
      "epoch:339,loss:0.3089979588985443,train accuracy:0.9375\n",
      "epoch:340,loss:0.08810855448246002,train accuracy:0.984375\n",
      "epoch 340,learning rate:0.0005582661385478637\n",
      "--epoch:340,loss:1.5544341802597046,test accuracy:0.8515625\n",
      "epoch:341,loss:0.05474353954195976,train accuracy:0.9921875\n",
      "epoch:342,loss:0.301843523979187,train accuracy:0.96875\n",
      "epoch:343,loss:0.039749663323163986,train accuracy:0.9765625\n",
      "epoch:344,loss:0.19367459416389465,train accuracy:0.9765625\n",
      "epoch:345,loss:0.027979161590337753,train accuracy:0.984375\n",
      "epoch 345,learning rate:0.000552683477162385\n",
      "--epoch:345,loss:1.642283320426941,test accuracy:0.8515625\n",
      "epoch:346,loss:0.05896997079253197,train accuracy:0.9765625\n",
      "epoch:347,loss:0.1900925636291504,train accuracy:0.96875\n",
      "epoch:348,loss:0.21922869980335236,train accuracy:0.984375\n",
      "epoch:349,loss:0.010095043107867241,train accuracy:0.9921875\n",
      "epoch:350,loss:0.12284787744283676,train accuracy:0.96875\n",
      "epoch 350,learning rate:0.0005471566423907612\n",
      "--epoch:350,loss:0.5970295071601868,test accuracy:0.90625\n",
      "epoch:351,loss:0.17755664885044098,train accuracy:0.9765625\n",
      "epoch:352,loss:0.06984519958496094,train accuracy:0.9921875\n",
      "epoch:353,loss:0.0010471377754583955,train accuracy:1.0\n",
      "epoch:354,loss:0.11721867322921753,train accuracy:0.9765625\n",
      "epoch:355,loss:0.17176835238933563,train accuracy:0.984375\n",
      "epoch 355,learning rate:0.0005416850759668536\n",
      "--epoch:355,loss:1.8022799491882324,test accuracy:0.8203125\n",
      "epoch:356,loss:0.11064416915178299,train accuracy:0.984375\n",
      "epoch:357,loss:0.0912790596485138,train accuracy:0.984375\n",
      "epoch:358,loss:0.1974492222070694,train accuracy:0.9609375\n",
      "epoch:359,loss:0.19793790578842163,train accuracy:0.9765625\n",
      "epoch:360,loss:0.4602380394935608,train accuracy:0.9765625\n",
      "epoch 360,learning rate:0.000536268225207185\n",
      "--epoch:360,loss:1.7817316055297852,test accuracy:0.8046875\n",
      "epoch:361,loss:0.2487059235572815,train accuracy:0.984375\n",
      "epoch:362,loss:0.17506131529808044,train accuracy:0.984375\n",
      "epoch:363,loss:0.03180604428052902,train accuracy:0.9921875\n",
      "epoch:364,loss:0.2371055781841278,train accuracy:0.96875\n",
      "epoch:365,loss:0.0003792508505284786,train accuracy:1.0\n",
      "epoch 365,learning rate:0.0005309055429551132\n",
      "--epoch:365,loss:2.417884349822998,test accuracy:0.828125\n",
      "epoch:366,loss:0.6849966645240784,train accuracy:0.9921875\n",
      "epoch:367,loss:0.5237315893173218,train accuracy:0.953125\n",
      "epoch:368,loss:0.23935002088546753,train accuracy:0.96875\n",
      "epoch:369,loss:0.148826003074646,train accuracy:0.9765625\n",
      "epoch:370,loss:0.017623567953705788,train accuracy:0.9921875\n",
      "epoch 370,learning rate:0.000525596487525562\n",
      "--epoch:370,loss:1.2149254083633423,test accuracy:0.84375\n",
      "epoch:371,loss:0.10774991661310196,train accuracy:0.9921875\n",
      "epoch:372,loss:0.22879013419151306,train accuracy:0.953125\n",
      "epoch:373,loss:0.08513322472572327,train accuracy:0.9921875\n",
      "epoch:374,loss:1.074488639831543,train accuracy:0.9765625\n",
      "epoch:375,loss:0.0003337784146424383,train accuracy:1.0\n",
      "epoch 375,learning rate:0.0005203405226503064\n",
      "--epoch:375,loss:1.1927900314331055,test accuracy:0.890625\n",
      "epoch:376,loss:0.1489490568637848,train accuracy:0.984375\n",
      "epoch:377,loss:0.11258555948734283,train accuracy:0.9765625\n",
      "epoch:378,loss:0.1697942167520523,train accuracy:0.9765625\n",
      "epoch:379,loss:0.21929441392421722,train accuracy:0.9765625\n",
      "epoch:380,loss:0.09909605979919434,train accuracy:0.96875\n",
      "epoch 380,learning rate:0.0005151371174238034\n",
      "--epoch:380,loss:1.378002643585205,test accuracy:0.875\n",
      "epoch:381,loss:0.01760771870613098,train accuracy:0.9921875\n",
      "epoch:382,loss:0.03925691545009613,train accuracy:0.9765625\n",
      "epoch:383,loss:0.2945774495601654,train accuracy:0.96875\n",
      "epoch:384,loss:0.09234050661325455,train accuracy:0.9921875\n",
      "epoch:385,loss:0.11369945108890533,train accuracy:0.9921875\n",
      "epoch 385,learning rate:0.0005099857462495653\n",
      "--epoch:385,loss:1.7433204650878906,test accuracy:0.859375\n",
      "epoch:386,loss:0.3514821529388428,train accuracy:0.9609375\n",
      "epoch:387,loss:0.2772584855556488,train accuracy:0.9453125\n",
      "epoch:388,loss:0.13570934534072876,train accuracy:0.9921875\n",
      "epoch:389,loss:0.212163507938385,train accuracy:0.9765625\n",
      "epoch:390,loss:0.06696620583534241,train accuracy:0.984375\n",
      "epoch 390,learning rate:0.0005048858887870696\n",
      "--epoch:390,loss:2.2726035118103027,test accuracy:0.859375\n",
      "epoch:391,loss:0.20733201503753662,train accuracy:0.984375\n",
      "epoch:392,loss:0.3202263414859772,train accuracy:0.9765625\n",
      "epoch:393,loss:0.2799888849258423,train accuracy:0.984375\n",
      "epoch:394,loss:0.0009307338041253388,train accuracy:1.0\n",
      "epoch:395,loss:0.15267091989517212,train accuracy:0.984375\n",
      "epoch 395,learning rate:0.0004998370298991989\n",
      "--epoch:395,loss:1.2653239965438843,test accuracy:0.90625\n",
      "epoch:396,loss:0.3519030213356018,train accuracy:0.9765625\n",
      "epoch:397,loss:0.07523350417613983,train accuracy:0.984375\n",
      "epoch:398,loss:0.14104866981506348,train accuracy:0.984375\n",
      "epoch:399,loss:0.4734683036804199,train accuracy:0.96875\n",
      "epoch:400,loss:0.13109835982322693,train accuracy:0.984375\n",
      "epoch 400,learning rate:0.000494838659600207\n",
      "--epoch:400,loss:1.86994206905365,test accuracy:0.8515625\n",
      "epoch:401,loss:0.1955696940422058,train accuracy:0.9765625\n",
      "epoch:402,loss:0.08214224874973297,train accuracy:0.984375\n",
      "epoch:403,loss:0.3529067039489746,train accuracy:0.96875\n",
      "epoch:404,loss:0.18611592054367065,train accuracy:0.984375\n",
      "epoch:405,loss:0.2843375504016876,train accuracy:0.984375\n",
      "epoch 405,learning rate:0.0004898902730042048\n",
      "--epoch:405,loss:0.9877446293830872,test accuracy:0.8984375\n",
      "epoch:406,loss:0.007086907979100943,train accuracy:1.0\n",
      "epoch:407,loss:0.19846302270889282,train accuracy:0.9609375\n",
      "epoch:408,loss:0.015444167889654636,train accuracy:0.9921875\n",
      "epoch:409,loss:0.01464916206896305,train accuracy:0.9921875\n",
      "epoch:410,loss:0.07913428544998169,train accuracy:0.984375\n",
      "epoch 410,learning rate:0.0004849913702741628\n",
      "--epoch:410,loss:1.8933563232421875,test accuracy:0.8046875\n",
      "epoch:411,loss:0.05501987040042877,train accuracy:0.984375\n",
      "epoch:412,loss:0.19960370659828186,train accuracy:0.9765625\n",
      "epoch:413,loss:0.13235819339752197,train accuracy:0.984375\n",
      "epoch:414,loss:0.036454662680625916,train accuracy:0.9921875\n",
      "epoch:415,loss:0.3437938094139099,train accuracy:0.984375\n",
      "epoch 415,learning rate:0.00048014145657142114\n",
      "--epoch:415,loss:1.4122507572174072,test accuracy:0.8671875\n",
      "epoch:416,loss:0.6561888456344604,train accuracy:0.96875\n",
      "epoch:417,loss:0.003407362150028348,train accuracy:1.0\n",
      "epoch:418,loss:0.18329843878746033,train accuracy:0.96875\n",
      "epoch:419,loss:0.022627346217632294,train accuracy:0.9921875\n",
      "epoch:420,loss:0.4666670560836792,train accuracy:0.96875\n",
      "epoch 420,learning rate:0.00047534004200570695\n",
      "--epoch:420,loss:1.6830390691757202,test accuracy:0.8515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:421,loss:0.22764043509960175,train accuracy:0.984375\n",
      "epoch:422,loss:0.004962262697517872,train accuracy:1.0\n",
      "epoch:423,loss:0.3769400417804718,train accuracy:0.9765625\n",
      "epoch:424,loss:0.10972348600625992,train accuracy:0.984375\n",
      "epoch:425,loss:0.08770225197076797,train accuracy:0.9765625\n",
      "epoch 425,learning rate:0.0004705866415856499\n",
      "--epoch:425,loss:1.3638253211975098,test accuracy:0.8984375\n",
      "epoch:426,loss:0.24507248401641846,train accuracy:0.9765625\n",
      "epoch:427,loss:9.83139470918104e-05,train accuracy:1.0\n",
      "epoch:428,loss:0.08447979390621185,train accuracy:0.9921875\n",
      "epoch:429,loss:0.09348877519369125,train accuracy:0.9765625\n",
      "epoch:430,loss:0.14603130519390106,train accuracy:0.984375\n",
      "epoch 430,learning rate:0.0004658807751697934\n",
      "--epoch:430,loss:2.5096983909606934,test accuracy:0.8359375\n",
      "epoch:431,loss:0.3194428086280823,train accuracy:0.9609375\n",
      "epoch:432,loss:0.11442673206329346,train accuracy:0.984375\n",
      "epoch:433,loss:0.19478538632392883,train accuracy:0.96875\n",
      "epoch:434,loss:0.02961244434118271,train accuracy:0.9921875\n",
      "epoch:435,loss:0.038810644298791885,train accuracy:0.984375\n",
      "epoch 435,learning rate:0.00046122196741809544\n",
      "--epoch:435,loss:1.467453956604004,test accuracy:0.8984375\n",
      "epoch:436,loss:0.1593863070011139,train accuracy:0.9921875\n",
      "epoch:437,loss:5.559578767133644e-06,train accuracy:1.0\n",
      "epoch:438,loss:0.0738525465130806,train accuracy:0.984375\n",
      "epoch:439,loss:0.38226285576820374,train accuracy:0.96875\n",
      "epoch:440,loss:0.005283767357468605,train accuracy:1.0\n",
      "epoch 440,learning rate:0.0004566097477439145\n",
      "--epoch:440,loss:3.1060519218444824,test accuracy:0.828125\n",
      "epoch:441,loss:0.43212100863456726,train accuracy:0.9765625\n",
      "epoch:442,loss:0.003910822328180075,train accuracy:1.0\n",
      "epoch:443,loss:0.0012049553915858269,train accuracy:1.0\n",
      "epoch:444,loss:0.24922287464141846,train accuracy:0.9375\n",
      "epoch:445,loss:0.09125975519418716,train accuracy:0.96875\n",
      "epoch 445,learning rate:0.00045204365026647533\n",
      "--epoch:445,loss:2.256683111190796,test accuracy:0.8125\n",
      "epoch:446,loss:0.03048885241150856,train accuracy:0.9765625\n",
      "epoch:447,loss:0.07538658380508423,train accuracy:0.9765625\n",
      "epoch:448,loss:0.10019830614328384,train accuracy:0.9765625\n",
      "epoch:449,loss:0.09305059909820557,train accuracy:0.984375\n",
      "epoch:450,loss:0.10666946321725845,train accuracy:0.9921875\n",
      "epoch 450,learning rate:0.0004475232137638106\n",
      "--epoch:450,loss:2.9126760959625244,test accuracy:0.84375\n",
      "epoch:451,loss:0.10560356080532074,train accuracy:0.984375\n",
      "epoch:452,loss:0.2832527458667755,train accuracy:0.984375\n",
      "epoch:453,loss:0.22809673845767975,train accuracy:0.984375\n",
      "epoch:454,loss:0.07796233892440796,train accuracy:0.96875\n",
      "epoch:455,loss:0.08268798887729645,train accuracy:0.9765625\n",
      "epoch 455,learning rate:0.0004430479816261725\n",
      "--epoch:455,loss:0.9162468910217285,test accuracy:0.90625\n",
      "epoch:456,loss:0.20155441761016846,train accuracy:0.953125\n",
      "epoch:457,loss:0.35056620836257935,train accuracy:0.96875\n",
      "epoch:458,loss:0.05899918079376221,train accuracy:0.9921875\n",
      "epoch:459,loss:0.39660581946372986,train accuracy:0.9765625\n",
      "epoch:460,loss:0.12354710698127747,train accuracy:0.984375\n",
      "epoch 460,learning rate:0.00043861750180991077\n",
      "--epoch:460,loss:3.2939324378967285,test accuracy:0.8203125\n",
      "epoch:461,loss:0.234935000538826,train accuracy:0.984375\n",
      "epoch:462,loss:0.26665782928466797,train accuracy:0.984375\n",
      "epoch:463,loss:0.6727556586265564,train accuracy:0.9765625\n",
      "epoch:464,loss:0.06728477776050568,train accuracy:0.9765625\n",
      "epoch:465,loss:0.36500084400177,train accuracy:0.9765625\n",
      "epoch 465,learning rate:0.00043423132679181164\n",
      "--epoch:465,loss:1.9821453094482422,test accuracy:0.8515625\n",
      "epoch:466,loss:0.3084731101989746,train accuracy:0.953125\n",
      "epoch:467,loss:0.030195556581020355,train accuracy:0.9921875\n",
      "epoch:468,loss:0.06861713528633118,train accuracy:0.9921875\n",
      "epoch:469,loss:0.49512946605682373,train accuracy:0.953125\n",
      "epoch:470,loss:0.03358207270503044,train accuracy:0.9921875\n",
      "epoch 470,learning rate:0.0004298890135238935\n",
      "--epoch:470,loss:2.81068754196167,test accuracy:0.8203125\n",
      "epoch:471,loss:0.06288567185401917,train accuracy:0.9921875\n",
      "epoch:472,loss:0.02939007058739662,train accuracy:0.9921875\n",
      "epoch:473,loss:0.094100721180439,train accuracy:0.984375\n",
      "epoch:474,loss:0.32911595702171326,train accuracy:0.96875\n",
      "epoch:475,loss:0.19234859943389893,train accuracy:0.984375\n",
      "epoch 475,learning rate:0.0004255901233886546\n",
      "--epoch:475,loss:2.499290704727173,test accuracy:0.828125\n",
      "epoch:476,loss:0.15874269604682922,train accuracy:0.984375\n",
      "epoch:477,loss:0.0011522667482495308,train accuracy:1.0\n",
      "epoch:478,loss:0.1137823760509491,train accuracy:0.9921875\n",
      "epoch:479,loss:0.5890834331512451,train accuracy:0.96875\n",
      "epoch:480,loss:0.0018772288458421826,train accuracy:1.0\n",
      "epoch 480,learning rate:0.00042133422215476804\n",
      "--epoch:480,loss:2.8317291736602783,test accuracy:0.8125\n",
      "epoch:481,loss:0.03852919861674309,train accuracy:0.9765625\n",
      "epoch:482,loss:0.04023779556155205,train accuracy:0.9921875\n",
      "epoch:483,loss:0.07536666840314865,train accuracy:0.9765625\n",
      "epoch:484,loss:0.24276109039783478,train accuracy:0.984375\n",
      "epoch:485,loss:0.008585663512349129,train accuracy:0.9921875\n",
      "epoch 485,learning rate:0.00041712087993322035\n",
      "--epoch:485,loss:1.6973594427108765,test accuracy:0.8828125\n",
      "epoch:486,loss:0.3987639546394348,train accuracy:0.96875\n",
      "epoch:487,loss:0.04288950562477112,train accuracy:0.9921875\n",
      "epoch:488,loss:0.0051532625220716,train accuracy:1.0\n",
      "epoch:489,loss:0.029169205576181412,train accuracy:0.9921875\n",
      "epoch:490,loss:0.08631663769483566,train accuracy:0.9765625\n",
      "epoch 490,learning rate:0.0004129496711338881\n",
      "--epoch:490,loss:2.829993724822998,test accuracy:0.8515625\n",
      "epoch:491,loss:0.04107113555073738,train accuracy:0.984375\n",
      "epoch:492,loss:0.10905171930789948,train accuracy:0.9921875\n",
      "epoch:493,loss:0.001354058156721294,train accuracy:1.0\n",
      "epoch:494,loss:0.13380146026611328,train accuracy:0.984375\n",
      "epoch:495,loss:3.0926623821869725e-06,train accuracy:1.0\n",
      "epoch 495,learning rate:0.0004088201744225492\n",
      "--epoch:495,loss:3.3737905025482178,test accuracy:0.8671875\n",
      "epoch:496,loss:0.7673264741897583,train accuracy:0.9765625\n",
      "epoch:497,loss:1.7213689716299996e-05,train accuracy:1.0\n",
      "epoch:498,loss:0.005518684163689613,train accuracy:1.0\n",
      "epoch:499,loss:0.17649835348129272,train accuracy:0.9765625\n",
      "epoch:500,loss:2.819840665324591e-05,train accuracy:1.0\n",
      "epoch 500,learning rate:0.0004047319726783237\n",
      "--epoch:500,loss:1.9760005474090576,test accuracy:0.84375\n",
      "epoch:501,loss:0.36490994691848755,train accuracy:0.9765625\n",
      "epoch:502,loss:0.29903286695480347,train accuracy:0.9765625\n",
      "epoch:503,loss:0.5234252214431763,train accuracy:0.9921875\n",
      "epoch:504,loss:0.016946369782090187,train accuracy:0.9921875\n",
      "epoch:505,loss:0.4148501455783844,train accuracy:0.96875\n",
      "epoch 505,learning rate:0.00040068465295154044\n",
      "--epoch:505,loss:1.8632698059082031,test accuracy:0.8671875\n",
      "epoch:506,loss:0.19360989332199097,train accuracy:0.984375\n",
      "epoch:507,loss:0.1098344475030899,train accuracy:0.9921875\n",
      "epoch:508,loss:0.11494378000497818,train accuracy:0.9921875\n",
      "epoch:509,loss:0.01337466575205326,train accuracy:0.9921875\n",
      "epoch:510,loss:0.1092442125082016,train accuracy:0.9921875\n",
      "epoch 510,learning rate:0.00039667780642202503\n",
      "--epoch:510,loss:3.0210063457489014,test accuracy:0.8203125\n",
      "epoch:511,loss:0.04467089846730232,train accuracy:0.984375\n",
      "epoch:512,loss:8.084043656708673e-06,train accuracy:1.0\n",
      "epoch:513,loss:5.358408088795841e-06,train accuracy:1.0\n",
      "epoch:514,loss:0.43511706590652466,train accuracy:0.9765625\n",
      "epoch:515,loss:0.07910068333148956,train accuracy:0.9921875\n",
      "epoch 515,learning rate:0.0003927110283578048\n",
      "--epoch:515,loss:2.2527785301208496,test accuracy:0.8671875\n",
      "epoch:516,loss:0.25539058446884155,train accuracy:0.984375\n",
      "epoch:517,loss:0.06082138046622276,train accuracy:0.984375\n",
      "epoch:518,loss:0.006881174631416798,train accuracy:0.9921875\n",
      "epoch:519,loss:0.2601636052131653,train accuracy:0.984375\n",
      "epoch:520,loss:0.1358589082956314,train accuracy:0.9765625\n",
      "epoch 520,learning rate:0.00038878391807422674\n",
      "--epoch:520,loss:2.808345079421997,test accuracy:0.859375\n",
      "epoch:521,loss:0.02727537229657173,train accuracy:0.9921875\n",
      "epoch:522,loss:0.5387985706329346,train accuracy:0.96875\n",
      "epoch:523,loss:0.05059013515710831,train accuracy:0.9921875\n",
      "epoch:524,loss:0.04731948301196098,train accuracy:0.9921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:525,loss:0.10310769826173782,train accuracy:0.9765625\n",
      "epoch 525,learning rate:0.0003848960788934845\n",
      "--epoch:525,loss:1.829229474067688,test accuracy:0.8671875\n",
      "epoch:526,loss:0.1753864288330078,train accuracy:0.9765625\n",
      "epoch:527,loss:0.048099640756845474,train accuracy:0.984375\n",
      "epoch:528,loss:0.003127384465187788,train accuracy:1.0\n",
      "epoch:529,loss:0.009235131554305553,train accuracy:0.9921875\n",
      "epoch:530,loss:0.1949600875377655,train accuracy:0.9765625\n",
      "epoch 530,learning rate:0.00038104711810454966\n",
      "--epoch:530,loss:2.8609447479248047,test accuracy:0.8203125\n",
      "epoch:531,loss:0.28448042273521423,train accuracy:0.9765625\n",
      "epoch:532,loss:0.1332232654094696,train accuracy:0.9921875\n",
      "epoch:533,loss:0.017975935712456703,train accuracy:0.9921875\n",
      "epoch:534,loss:0.04766406863927841,train accuracy:0.984375\n",
      "epoch:535,loss:0.03194030746817589,train accuracy:0.9921875\n",
      "epoch 535,learning rate:0.00037723664692350416\n",
      "--epoch:535,loss:2.954306125640869,test accuracy:0.8359375\n",
      "epoch:536,loss:0.059475116431713104,train accuracy:0.984375\n",
      "epoch:537,loss:0.07713930308818817,train accuracy:0.9765625\n",
      "epoch:538,loss:0.04471280425786972,train accuracy:0.9921875\n",
      "epoch:539,loss:0.23965266346931458,train accuracy:0.9765625\n",
      "epoch:540,loss:0.548301637172699,train accuracy:0.96875\n",
      "epoch 540,learning rate:0.00037346428045426913\n",
      "--epoch:540,loss:2.1734657287597656,test accuracy:0.875\n",
      "epoch:541,loss:0.08589638769626617,train accuracy:0.9921875\n",
      "epoch:542,loss:0.5650737881660461,train accuracy:0.984375\n",
      "epoch:543,loss:0.0006937850266695023,train accuracy:1.0\n",
      "epoch:544,loss:0.0041020275093615055,train accuracy:1.0\n",
      "epoch:545,loss:0.04580630362033844,train accuracy:0.9921875\n",
      "epoch 545,learning rate:0.00036972963764972643\n",
      "--epoch:545,loss:2.2451910972595215,test accuracy:0.8515625\n",
      "epoch:546,loss:0.768939733505249,train accuracy:0.9609375\n",
      "epoch:547,loss:0.25374895334243774,train accuracy:0.984375\n",
      "epoch:548,loss:0.14108484983444214,train accuracy:0.984375\n",
      "epoch:549,loss:0.18917259573936462,train accuracy:0.9609375\n",
      "epoch:550,loss:0.0027171396650373936,train accuracy:1.0\n",
      "epoch 550,learning rate:0.00036603234127322915\n",
      "--epoch:550,loss:2.5981850624084473,test accuracy:0.84375\n",
      "epoch:551,loss:7.44099111216201e-07,train accuracy:1.0\n",
      "epoch:552,loss:0.002423252211883664,train accuracy:1.0\n",
      "epoch:553,loss:0.7783264517784119,train accuracy:0.9765625\n",
      "epoch:554,loss:0.16417965292930603,train accuracy:0.984375\n",
      "epoch:555,loss:0.0007358469883911312,train accuracy:1.0\n",
      "epoch 555,learning rate:0.00036237201786049685\n",
      "--epoch:555,loss:2.792250871658325,test accuracy:0.828125\n",
      "epoch:556,loss:0.08658759295940399,train accuracy:0.9921875\n",
      "epoch:557,loss:0.10374487936496735,train accuracy:0.9765625\n",
      "epoch:558,loss:5.024408892495558e-05,train accuracy:1.0\n",
      "epoch:559,loss:0.075595423579216,train accuracy:0.9921875\n",
      "epoch:560,loss:0.07892277836799622,train accuracy:0.984375\n",
      "epoch 560,learning rate:0.0003587482976818919\n",
      "--epoch:560,loss:2.4721579551696777,test accuracy:0.875\n",
      "epoch:561,loss:0.0010058404877781868,train accuracy:1.0\n",
      "epoch:562,loss:0.005897304974496365,train accuracy:1.0\n",
      "epoch:563,loss:0.06658504903316498,train accuracy:0.9765625\n",
      "epoch:564,loss:4.199136583338259e-06,train accuracy:1.0\n",
      "epoch:565,loss:0.13351695239543915,train accuracy:0.984375\n",
      "epoch 565,learning rate:0.00035516081470507297\n",
      "--epoch:565,loss:2.3472776412963867,test accuracy:0.8203125\n",
      "epoch:566,loss:9.337143274024129e-05,train accuracy:1.0\n",
      "epoch:567,loss:0.24455857276916504,train accuracy:0.984375\n",
      "epoch:568,loss:0.10649549961090088,train accuracy:0.984375\n",
      "epoch:569,loss:0.014007006771862507,train accuracy:0.9921875\n",
      "epoch:570,loss:0.48860833048820496,train accuracy:0.96875\n",
      "epoch 570,learning rate:0.0003516092065580222\n",
      "--epoch:570,loss:1.6679291725158691,test accuracy:0.890625\n",
      "epoch:571,loss:0.10199941694736481,train accuracy:0.984375\n",
      "epoch:572,loss:0.03100283071398735,train accuracy:0.9921875\n",
      "epoch:573,loss:0.02037407085299492,train accuracy:0.9921875\n",
      "epoch:574,loss:0.0006229552091099322,train accuracy:1.0\n",
      "epoch:575,loss:0.028286686167120934,train accuracy:0.9921875\n",
      "epoch 575,learning rate:0.000348093114492442\n",
      "--epoch:575,loss:2.6967036724090576,test accuracy:0.84375\n",
      "epoch:576,loss:0.3270193934440613,train accuracy:0.984375\n",
      "epoch:577,loss:0.22025930881500244,train accuracy:0.984375\n",
      "epoch:578,loss:0.01360054686665535,train accuracy:0.9921875\n",
      "epoch:579,loss:0.00040125646046362817,train accuracy:1.0\n",
      "epoch:580,loss:0.06405016034841537,train accuracy:0.9921875\n",
      "epoch 580,learning rate:0.00034461218334751756\n",
      "--epoch:580,loss:2.8174405097961426,test accuracy:0.8203125\n",
      "epoch:581,loss:0.00013150593440514058,train accuracy:1.0\n",
      "epoch:582,loss:0.1108069121837616,train accuracy:0.984375\n",
      "epoch:583,loss:4.8879985115490854e-05,train accuracy:1.0\n",
      "epoch:584,loss:0.25543832778930664,train accuracy:0.984375\n",
      "epoch:585,loss:0.023128053173422813,train accuracy:0.9921875\n",
      "epoch 585,learning rate:0.0003411660615140424\n",
      "--epoch:585,loss:1.9984710216522217,test accuracy:0.8515625\n",
      "epoch:586,loss:0.3706090748310089,train accuracy:0.9765625\n",
      "epoch:587,loss:0.017721137031912804,train accuracy:0.9921875\n",
      "epoch:588,loss:0.03849891200661659,train accuracy:0.984375\n",
      "epoch:589,loss:0.36908969283103943,train accuracy:0.953125\n",
      "epoch:590,loss:0.0007500920328311622,train accuracy:1.0\n",
      "epoch 590,learning rate:0.00033775440089890197\n",
      "--epoch:590,loss:2.558438539505005,test accuracy:0.828125\n",
      "epoch:591,loss:5.679777586919954e-06,train accuracy:1.0\n",
      "epoch:592,loss:0.3766237795352936,train accuracy:0.9765625\n",
      "epoch:593,loss:0.000661608180962503,train accuracy:1.0\n",
      "epoch:594,loss:0.19638334214687347,train accuracy:0.9765625\n",
      "epoch:595,loss:0.25459468364715576,train accuracy:0.984375\n",
      "epoch 595,learning rate:0.000334376856889913\n",
      "--epoch:595,loss:0.7714018821716309,test accuracy:0.8984375\n",
      "epoch:596,loss:0.13422532379627228,train accuracy:0.984375\n",
      "epoch:597,loss:0.0007949310820549726,train accuracy:1.0\n",
      "epoch:598,loss:0.013869019225239754,train accuracy:0.9921875\n",
      "epoch:599,loss:0.10508179664611816,train accuracy:0.9765625\n",
      "epoch:600,loss:0.0036403443664312363,train accuracy:1.0\n",
      "epoch 600,learning rate:0.00033103308832101386\n",
      "--epoch:600,loss:2.293745994567871,test accuracy:0.84375\n",
      "epoch:601,loss:0.1256745606660843,train accuracy:0.984375\n",
      "epoch:602,loss:0.013759633526206017,train accuracy:0.9921875\n",
      "epoch:603,loss:0.13529831171035767,train accuracy:0.984375\n",
      "epoch:604,loss:4.084446118213236e-06,train accuracy:1.0\n",
      "epoch:605,loss:0.0643211081624031,train accuracy:0.9921875\n",
      "epoch 605,learning rate:0.00032772275743780374\n",
      "--epoch:605,loss:2.454275131225586,test accuracy:0.859375\n",
      "epoch:606,loss:0.006260726135224104,train accuracy:1.0\n",
      "epoch:607,loss:0.3691655695438385,train accuracy:0.96875\n",
      "epoch:608,loss:0.12953847646713257,train accuracy:0.96875\n",
      "epoch:609,loss:0.01871112734079361,train accuracy:0.9921875\n",
      "epoch:610,loss:0.2462950348854065,train accuracy:0.9765625\n",
      "epoch 610,learning rate:0.0003244455298634257\n",
      "--epoch:610,loss:2.0238418579101562,test accuracy:0.8515625\n",
      "epoch:611,loss:0.15457764267921448,train accuracy:0.9765625\n",
      "epoch:612,loss:0.38291025161743164,train accuracy:0.9921875\n",
      "epoch:613,loss:0.054870858788490295,train accuracy:0.984375\n",
      "epoch:614,loss:0.5145186185836792,train accuracy:0.9609375\n",
      "epoch:615,loss:0.03349264711141586,train accuracy:0.9921875\n",
      "epoch 615,learning rate:0.0003212010745647914\n",
      "--epoch:615,loss:2.7459850311279297,test accuracy:0.8671875\n",
      "epoch:616,loss:0.12172292917966843,train accuracy:0.9921875\n",
      "epoch:617,loss:0.0020891756284981966,train accuracy:1.0\n",
      "epoch:618,loss:0.027140891179442406,train accuracy:0.9921875\n",
      "epoch:619,loss:0.06585466861724854,train accuracy:0.9921875\n",
      "epoch:620,loss:0.03369865566492081,train accuracy:0.9765625\n",
      "epoch 620,learning rate:0.0003179890638191435\n",
      "--epoch:620,loss:1.8208028078079224,test accuracy:0.8828125\n",
      "epoch:621,loss:0.23600821197032928,train accuracy:0.984375\n",
      "epoch:622,loss:0.2255539894104004,train accuracy:0.9765625\n",
      "epoch:623,loss:0.19760461151599884,train accuracy:0.984375\n",
      "epoch:624,loss:0.4532148838043213,train accuracy:0.96875\n",
      "epoch:625,loss:0.3453900218009949,train accuracy:0.9609375\n",
      "epoch 625,learning rate:0.0003148091731809521\n",
      "--epoch:625,loss:2.004746675491333,test accuracy:0.859375\n",
      "epoch:626,loss:0.013070644810795784,train accuracy:0.9921875\n",
      "epoch:627,loss:0.1274130493402481,train accuracy:0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:628,loss:0.11744370311498642,train accuracy:0.9765625\n",
      "epoch:629,loss:0.19622330367565155,train accuracy:0.984375\n",
      "epoch:630,loss:0.11769367754459381,train accuracy:0.984375\n",
      "--epoch:630,loss:3.8160436153411865,test accuracy:0.78125\n",
      "epoch:631,loss:0.020655330270528793,train accuracy:0.9921875\n",
      "epoch:632,loss:0.039888784289360046,train accuracy:0.9921875\n",
      "epoch:633,loss:0.004210059996694326,train accuracy:1.0\n",
      "epoch:634,loss:0.05061301589012146,train accuracy:0.9921875\n",
      "epoch:635,loss:0.5598135590553284,train accuracy:0.984375\n",
      "epoch 635,learning rate:0.0003116610814491426\n",
      "--epoch:635,loss:3.3699593544006348,test accuracy:0.8203125\n",
      "epoch:636,loss:5.411079473560676e-05,train accuracy:1.0\n",
      "epoch:637,loss:0.04343274608254433,train accuracy:0.9921875\n",
      "epoch:638,loss:0.21525804698467255,train accuracy:0.9921875\n",
      "epoch:639,loss:0.07236488163471222,train accuracy:0.984375\n",
      "epoch:640,loss:0.09733662009239197,train accuracy:0.984375\n",
      "epoch 640,learning rate:0.00030854447063465116\n",
      "--epoch:640,loss:3.617354393005371,test accuracy:0.8125\n",
      "epoch:641,loss:0.00952488835901022,train accuracy:0.9921875\n",
      "epoch:642,loss:0.32905977964401245,train accuracy:0.9609375\n",
      "epoch:643,loss:0.15919677913188934,train accuracy:0.9921875\n",
      "epoch:644,loss:0.027076557278633118,train accuracy:0.9921875\n",
      "epoch:645,loss:0.17166534066200256,train accuracy:0.984375\n",
      "epoch 645,learning rate:0.00030545902592830465\n",
      "--epoch:645,loss:2.5625622272491455,test accuracy:0.84375\n",
      "epoch:646,loss:0.03224577754735947,train accuracy:0.9921875\n",
      "epoch:647,loss:0.003085389267653227,train accuracy:1.0\n",
      "epoch:648,loss:0.009027233347296715,train accuracy:0.9921875\n",
      "epoch:649,loss:0.3315850496292114,train accuracy:0.9765625\n",
      "epoch:650,loss:0.0038295791018754244,train accuracy:1.0\n",
      "epoch 650,learning rate:0.00030240443566902157\n",
      "--epoch:650,loss:2.827831745147705,test accuracy:0.828125\n",
      "epoch:651,loss:2.143618075933773e-06,train accuracy:1.0\n",
      "epoch:652,loss:0.006603509187698364,train accuracy:0.9921875\n",
      "epoch:653,loss:0.03377983346581459,train accuracy:0.9921875\n",
      "epoch:654,loss:0.12195635586977005,train accuracy:0.984375\n",
      "epoch:655,loss:0.1371336579322815,train accuracy:0.9921875\n",
      "epoch 655,learning rate:0.00029938039131233136\n",
      "--epoch:655,loss:3.3334202766418457,test accuracy:0.84375\n",
      "epoch:656,loss:0.00020974398648831993,train accuracy:1.0\n",
      "epoch:657,loss:0.35155239701271057,train accuracy:0.984375\n",
      "epoch:658,loss:0.03072798065841198,train accuracy:0.9921875\n",
      "epoch:659,loss:0.32029932737350464,train accuracy:0.9921875\n",
      "epoch:660,loss:0.034801553934812546,train accuracy:0.9921875\n",
      "epoch 660,learning rate:0.00029638658739920804\n",
      "--epoch:660,loss:3.071497917175293,test accuracy:0.8125\n",
      "epoch:661,loss:0.002533534076064825,train accuracy:1.0\n",
      "epoch:662,loss:0.14705774188041687,train accuracy:0.9609375\n",
      "epoch:663,loss:0.4632018506526947,train accuracy:0.96875\n",
      "epoch:664,loss:0.0001634869258850813,train accuracy:1.0\n",
      "epoch:665,loss:0.20625171065330505,train accuracy:0.9921875\n",
      "epoch 665,learning rate:0.000293422721525216\n",
      "--epoch:665,loss:2.2639288902282715,test accuracy:0.8671875\n",
      "epoch:666,loss:0.04372308775782585,train accuracy:0.9921875\n",
      "epoch:667,loss:8.826380508253351e-06,train accuracy:1.0\n",
      "epoch:668,loss:0.3595685064792633,train accuracy:0.984375\n",
      "epoch:669,loss:0.3552963435649872,train accuracy:0.9765625\n",
      "epoch:670,loss:0.013035428710281849,train accuracy:0.9921875\n",
      "epoch 670,learning rate:0.0002904884943099638\n",
      "--epoch:670,loss:2.3744711875915527,test accuracy:0.8828125\n",
      "epoch:671,loss:0.1563112586736679,train accuracy:0.984375\n",
      "epoch:672,loss:0.17114511132240295,train accuracy:0.9765625\n",
      "epoch:673,loss:1.8626430176027498e-08,train accuracy:1.0\n",
      "epoch:674,loss:0.44850772619247437,train accuracy:0.9765625\n",
      "epoch:675,loss:0.7855648994445801,train accuracy:0.9765625\n",
      "epoch 675,learning rate:0.0002875836093668642\n",
      "--epoch:675,loss:1.0058311223983765,test accuracy:0.9140625\n",
      "epoch:676,loss:3.047941754630301e-05,train accuracy:1.0\n",
      "epoch:677,loss:0.000133037319756113,train accuracy:1.0\n",
      "epoch:678,loss:0.3567139804363251,train accuracy:0.9765625\n",
      "epoch:679,loss:0.28117835521698,train accuracy:0.984375\n",
      "epoch:680,loss:5.853154289070517e-05,train accuracy:1.0\n",
      "epoch 680,learning rate:0.00028470777327319557\n",
      "--epoch:680,loss:2.9991626739501953,test accuracy:0.8203125\n",
      "epoch:681,loss:0.29579591751098633,train accuracy:0.984375\n",
      "epoch:682,loss:0.027722418308258057,train accuracy:0.9921875\n",
      "epoch:683,loss:0.07645433396100998,train accuracy:0.984375\n",
      "epoch:684,loss:0.06981881707906723,train accuracy:0.9921875\n",
      "epoch:685,loss:0.11080676317214966,train accuracy:0.9921875\n",
      "epoch 685,learning rate:0.0002818606955404636\n",
      "--epoch:685,loss:1.838904857635498,test accuracy:0.8671875\n",
      "epoch:686,loss:0.1379072219133377,train accuracy:0.984375\n",
      "epoch:687,loss:0.0015351010952144861,train accuracy:1.0\n",
      "epoch:688,loss:0.011196611449122429,train accuracy:0.9921875\n",
      "epoch:689,loss:0.07550957798957825,train accuracy:0.9921875\n",
      "epoch:690,loss:0.18243691325187683,train accuracy:0.984375\n",
      "epoch 690,learning rate:0.00027904208858505896\n",
      "--epoch:690,loss:2.8084075450897217,test accuracy:0.84375\n",
      "epoch:691,loss:0.2833319902420044,train accuracy:0.9921875\n",
      "epoch:692,loss:0.03369181975722313,train accuracy:0.9921875\n",
      "epoch:693,loss:0.3590238690376282,train accuracy:0.9765625\n",
      "epoch:694,loss:0.09192617982625961,train accuracy:0.984375\n",
      "epoch:695,loss:0.045316390693187714,train accuracy:0.984375\n",
      "epoch 695,learning rate:0.00027625166769920835\n",
      "--epoch:695,loss:1.1920807361602783,test accuracy:0.8984375\n",
      "epoch:696,loss:0.08548492193222046,train accuracy:0.9921875\n",
      "epoch:697,loss:8.885483111953363e-06,train accuracy:1.0\n",
      "epoch:698,loss:0.28189483284950256,train accuracy:0.9765625\n",
      "epoch:699,loss:0.26365774869918823,train accuracy:0.96875\n",
      "epoch:700,loss:0.1296183168888092,train accuracy:0.984375\n",
      "epoch 700,learning rate:0.00027348915102221624\n",
      "--epoch:700,loss:1.7797319889068604,test accuracy:0.875\n",
      "epoch:701,loss:0.08475319296121597,train accuracy:0.984375\n",
      "epoch:702,loss:0.042382605373859406,train accuracy:0.9921875\n",
      "epoch:703,loss:1.2386556136334548e-07,train accuracy:1.0\n",
      "epoch:704,loss:0.18833473324775696,train accuracy:0.984375\n",
      "epoch:705,loss:0.10366448014974594,train accuracy:0.984375\n",
      "epoch 705,learning rate:0.0002707542595119941\n",
      "--epoch:705,loss:2.9060187339782715,test accuracy:0.8359375\n",
      "epoch:706,loss:0.012208287604153156,train accuracy:0.9921875\n",
      "epoch:707,loss:0.1223808228969574,train accuracy:0.9921875\n",
      "epoch:708,loss:0.049160413444042206,train accuracy:0.9921875\n",
      "epoch:709,loss:0.25120386481285095,train accuracy:0.9765625\n",
      "epoch:710,loss:0.04006950557231903,train accuracy:0.984375\n",
      "epoch 710,learning rate:0.00026804671691687415\n",
      "--epoch:710,loss:2.835109233856201,test accuracy:0.828125\n",
      "epoch:711,loss:0.008920043706893921,train accuracy:0.9921875\n",
      "epoch:712,loss:0.012188393622636795,train accuracy:0.9921875\n",
      "epoch:713,loss:0.20344670116901398,train accuracy:0.9765625\n",
      "epoch:714,loss:0.035091277211904526,train accuracy:0.9921875\n",
      "epoch:715,loss:0.031054405495524406,train accuracy:0.9921875\n",
      "epoch 715,learning rate:0.0002653662497477054\n",
      "--epoch:715,loss:2.60178279876709,test accuracy:0.8125\n",
      "epoch:716,loss:0.30813267827033997,train accuracy:0.984375\n",
      "epoch:717,loss:0.0013806677889078856,train accuracy:1.0\n",
      "epoch:718,loss:0.00627527991309762,train accuracy:0.9921875\n",
      "epoch:719,loss:0.0903819277882576,train accuracy:0.984375\n",
      "epoch:720,loss:0.36329734325408936,train accuracy:0.984375\n",
      "epoch 720,learning rate:0.00026271258725022833\n",
      "--epoch:720,loss:2.918990135192871,test accuracy:0.8359375\n",
      "epoch:721,loss:0.23462198674678802,train accuracy:0.984375\n",
      "epoch:722,loss:4.224756594339851e-06,train accuracy:1.0\n",
      "epoch:723,loss:0.3887093663215637,train accuracy:0.9765625\n",
      "epoch:724,loss:0.08800937980413437,train accuracy:0.9921875\n",
      "epoch:725,loss:0.05807723477482796,train accuracy:0.9921875\n",
      "epoch 725,learning rate:0.000260085461377726\n",
      "--epoch:725,loss:3.7690677642822266,test accuracy:0.8046875\n",
      "epoch:726,loss:0.016880467534065247,train accuracy:0.9921875\n",
      "epoch:727,loss:0.0931728258728981,train accuracy:0.9921875\n",
      "epoch:728,loss:0.5670838356018066,train accuracy:0.9765625\n",
      "epoch:729,loss:9.86768372968072e-06,train accuracy:1.0\n",
      "epoch:730,loss:0.5082972049713135,train accuracy:0.9921875\n",
      "epoch 730,learning rate:0.00025748460676394875\n",
      "--epoch:730,loss:2.5105819702148438,test accuracy:0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:731,loss:0.001699978020042181,train accuracy:1.0\n",
      "epoch:732,loss:0.3918132781982422,train accuracy:0.9765625\n",
      "epoch:733,loss:0.14611706137657166,train accuracy:0.9765625\n",
      "epoch:734,loss:0.009467218071222305,train accuracy:0.9921875\n",
      "epoch:735,loss:0.0036882830318063498,train accuracy:1.0\n",
      "epoch 735,learning rate:0.00025490976069630927\n",
      "--epoch:735,loss:2.095144033432007,test accuracy:0.859375\n",
      "epoch:736,loss:0.08720417320728302,train accuracy:0.9921875\n",
      "epoch:737,loss:0.388663649559021,train accuracy:0.984375\n",
      "epoch:738,loss:1.8626440834168534e-08,train accuracy:1.0\n",
      "epoch:739,loss:2.600793777673971e-06,train accuracy:1.0\n",
      "epoch:740,loss:0.0007780772284604609,train accuracy:1.0\n",
      "epoch 740,learning rate:0.00025236066308934616\n",
      "--epoch:740,loss:1.9450596570968628,test accuracy:0.8984375\n",
      "epoch:741,loss:0.2499639391899109,train accuracy:0.9765625\n",
      "epoch:742,loss:0.035179127007722855,train accuracy:0.9921875\n",
      "epoch:743,loss:0.04826473444700241,train accuracy:0.9921875\n",
      "epoch:744,loss:0.09219756722450256,train accuracy:0.984375\n",
      "epoch:745,loss:0.04115573316812515,train accuracy:0.984375\n",
      "epoch 745,learning rate:0.0002498370564584527\n",
      "--epoch:745,loss:2.7154335975646973,test accuracy:0.859375\n",
      "epoch:746,loss:0.0001580522075528279,train accuracy:1.0\n",
      "epoch:747,loss:0.08568954467773438,train accuracy:0.984375\n",
      "epoch:748,loss:0.00020653782121371478,train accuracy:1.0\n",
      "epoch:749,loss:0.21747833490371704,train accuracy:0.9921875\n",
      "epoch:750,loss:2.1254949388094246e-05,train accuracy:1.0\n",
      "epoch 750,learning rate:0.0002473386858938682\n",
      "--epoch:750,loss:3.732083320617676,test accuracy:0.828125\n",
      "epoch:751,loss:0.2437789887189865,train accuracy:0.96875\n",
      "epoch:752,loss:0.13606563210487366,train accuracy:0.9765625\n",
      "epoch:753,loss:0.2556031048297882,train accuracy:0.9765625\n",
      "epoch:754,loss:0.06153774634003639,train accuracy:0.9921875\n",
      "epoch:755,loss:0.19489139318466187,train accuracy:0.984375\n",
      "epoch 755,learning rate:0.0002448652990349295\n",
      "--epoch:755,loss:1.7877899408340454,test accuracy:0.859375\n",
      "epoch:756,loss:0.19181686639785767,train accuracy:0.9765625\n",
      "epoch:757,loss:0.030361711978912354,train accuracy:0.9921875\n",
      "epoch:758,loss:0.11211399734020233,train accuracy:0.984375\n",
      "epoch:759,loss:0.00022846402134746313,train accuracy:1.0\n",
      "epoch:760,loss:1.4528532688018458e-07,train accuracy:1.0\n",
      "epoch 760,learning rate:0.0002424166460445802\n",
      "--epoch:760,loss:3.120563268661499,test accuracy:0.828125\n",
      "epoch:761,loss:0.11332030594348907,train accuracy:0.984375\n",
      "epoch:762,loss:0.3502846956253052,train accuracy:0.984375\n",
      "epoch:763,loss:0.02314915880560875,train accuracy:0.9921875\n",
      "epoch:764,loss:0.005332647357136011,train accuracy:1.0\n",
      "epoch:765,loss:0.049952443689107895,train accuracy:0.9921875\n",
      "epoch 765,learning rate:0.0002399924795841344\n",
      "--epoch:765,loss:3.0836076736450195,test accuracy:0.8203125\n",
      "epoch:766,loss:0.0010366932256147265,train accuracy:1.0\n",
      "epoch:767,loss:0.23893621563911438,train accuracy:0.9921875\n",
      "epoch:768,loss:0.05526502802968025,train accuracy:0.984375\n",
      "epoch:769,loss:0.36463165283203125,train accuracy:0.984375\n",
      "epoch:770,loss:0.0,train accuracy:1.0\n",
      "epoch 770,learning rate:0.00023759255478829306\n",
      "--epoch:770,loss:2.26364803314209,test accuracy:0.890625\n",
      "epoch:771,loss:0.3286793828010559,train accuracy:0.984375\n",
      "epoch:772,loss:5.5700820666970685e-06,train accuracy:1.0\n",
      "epoch:773,loss:9.313225191043273e-10,train accuracy:1.0\n",
      "epoch:774,loss:0.017440740019083023,train accuracy:0.9921875\n",
      "epoch:775,loss:0.31460267305374146,train accuracy:0.9921875\n",
      "epoch 775,learning rate:0.00023521662924041014\n",
      "--epoch:775,loss:1.4713181257247925,test accuracy:0.9140625\n",
      "epoch:776,loss:0.0005947861936874688,train accuracy:1.0\n",
      "epoch:777,loss:8.893650829122635e-07,train accuracy:1.0\n",
      "epoch:778,loss:0.044259265065193176,train accuracy:0.984375\n",
      "epoch:779,loss:0.4465217888355255,train accuracy:0.984375\n",
      "epoch:780,loss:0.3858920931816101,train accuracy:0.9609375\n",
      "epoch 780,learning rate:0.00023286446294800602\n",
      "--epoch:780,loss:3.3072116374969482,test accuracy:0.8203125\n",
      "epoch:781,loss:0.24935950338840485,train accuracy:0.9921875\n",
      "epoch:782,loss:0.008103374391794205,train accuracy:1.0\n",
      "epoch:783,loss:0.30590906739234924,train accuracy:0.9765625\n",
      "epoch:784,loss:0.009690088219940662,train accuracy:0.9921875\n",
      "epoch:785,loss:0.5084913372993469,train accuracy:0.984375\n",
      "epoch 785,learning rate:0.00023053581831852595\n",
      "--epoch:785,loss:1.9756135940551758,test accuracy:0.875\n",
      "epoch:786,loss:2.9802279755131167e-08,train accuracy:1.0\n",
      "epoch:787,loss:0.042170483618974686,train accuracy:0.9921875\n",
      "epoch:788,loss:0.00012103017797926441,train accuracy:1.0\n",
      "epoch:789,loss:3.682538135763025e-06,train accuracy:1.0\n",
      "epoch:790,loss:0.0744699165225029,train accuracy:0.9921875\n",
      "epoch 790,learning rate:0.0002282304601353407\n",
      "--epoch:790,loss:3.9100723266601562,test accuracy:0.8203125\n",
      "epoch:791,loss:0.1518561691045761,train accuracy:0.9765625\n",
      "epoch:792,loss:0.04957098886370659,train accuracy:0.984375\n",
      "epoch:793,loss:0.05675842985510826,train accuracy:0.9921875\n",
      "epoch:794,loss:0.7141055464744568,train accuracy:0.96875\n",
      "epoch:795,loss:0.298019677400589,train accuracy:0.9921875\n",
      "epoch 795,learning rate:0.00022594815553398729\n",
      "--epoch:795,loss:2.5485825538635254,test accuracy:0.8359375\n",
      "epoch:796,loss:1.0116200428456068e-05,train accuracy:1.0\n",
      "epoch:797,loss:0.011339345946907997,train accuracy:0.9921875\n",
      "epoch:798,loss:0.31330856680870056,train accuracy:0.9765625\n",
      "epoch:799,loss:0.017990274354815483,train accuracy:0.9921875\n",
      "epoch:800,loss:0.06196592003107071,train accuracy:0.984375\n",
      "epoch 800,learning rate:0.0002236886739786474\n",
      "--epoch:800,loss:2.817553997039795,test accuracy:0.84375\n",
      "epoch:801,loss:0.07884108275175095,train accuracy:0.984375\n",
      "epoch:802,loss:2.6226418412989005e-05,train accuracy:1.0\n",
      "epoch:803,loss:2.3632641386939213e-05,train accuracy:1.0\n",
      "epoch:804,loss:0.5303024053573608,train accuracy:0.9765625\n",
      "epoch:805,loss:0.3893863558769226,train accuracy:0.9765625\n",
      "epoch 805,learning rate:0.00022145178723886094\n",
      "--epoch:805,loss:2.7139203548431396,test accuracy:0.875\n",
      "epoch:806,loss:0.26282456517219543,train accuracy:0.984375\n",
      "epoch:807,loss:0.001718914951197803,train accuracy:1.0\n",
      "epoch:808,loss:0.06625601649284363,train accuracy:0.984375\n",
      "epoch:809,loss:0.7867960929870605,train accuracy:0.9765625\n",
      "epoch:810,loss:0.0001249383931281045,train accuracy:1.0\n",
      "epoch 810,learning rate:0.00021923726936647233\n",
      "--epoch:810,loss:2.6155450344085693,test accuracy:0.8515625\n",
      "epoch:811,loss:2.1678215489373542e-06,train accuracy:1.0\n",
      "epoch:812,loss:0.5473992824554443,train accuracy:0.9765625\n",
      "epoch:813,loss:0.040000200271606445,train accuracy:0.9921875\n",
      "epoch:814,loss:0.07981660962104797,train accuracy:0.9921875\n",
      "epoch:815,loss:0.0037120822817087173,train accuracy:1.0\n",
      "--epoch:815,loss:3.7646493911743164,test accuracy:0.78125\n",
      "epoch:816,loss:0.000167696169228293,train accuracy:1.0\n",
      "epoch:817,loss:0.031334128230810165,train accuracy:0.9921875\n",
      "epoch:818,loss:0.15289784967899323,train accuracy:0.9765625\n",
      "epoch:819,loss:5.466136644827202e-05,train accuracy:1.0\n",
      "epoch:820,loss:0.011600564233958721,train accuracy:0.9921875\n",
      "epoch 820,learning rate:0.0002170448966728076\n",
      "--epoch:820,loss:3.04940128326416,test accuracy:0.8203125\n",
      "epoch:821,loss:0.0014548437902703881,train accuracy:1.0\n",
      "epoch:822,loss:0.23107846081256866,train accuracy:0.984375\n",
      "epoch:823,loss:0.0933070257306099,train accuracy:0.984375\n",
      "epoch:824,loss:0.10990723967552185,train accuracy:0.9921875\n",
      "epoch:825,loss:0.4069121479988098,train accuracy:0.9921875\n",
      "epoch 825,learning rate:0.00021487444770607953\n",
      "--epoch:825,loss:3.116128444671631,test accuracy:0.859375\n",
      "epoch:826,loss:0.0006480827578343451,train accuracy:1.0\n",
      "epoch:827,loss:0.007702749688178301,train accuracy:0.9921875\n",
      "epoch:828,loss:0.028616271913051605,train accuracy:0.9921875\n",
      "epoch:829,loss:0.009174367412924767,train accuracy:0.9921875\n",
      "epoch:830,loss:2.123395717035237e-07,train accuracy:1.0\n",
      "epoch 830,learning rate:0.00021272570322901873\n",
      "--epoch:830,loss:2.1964597702026367,test accuracy:0.8984375\n",
      "epoch:831,loss:0.02334098517894745,train accuracy:0.984375\n",
      "epoch:832,loss:0.1371544897556305,train accuracy:0.9765625\n",
      "epoch:833,loss:0.17256128787994385,train accuracy:0.9921875\n",
      "epoch:834,loss:0.21995797753334045,train accuracy:0.9765625\n",
      "epoch:835,loss:0.24493686854839325,train accuracy:0.984375\n",
      "epoch 835,learning rate:0.00021059844619672854\n",
      "--epoch:835,loss:3.5796797275543213,test accuracy:0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:836,loss:0.3257191479206085,train accuracy:0.9765625\n",
      "epoch:837,loss:0.031184932217001915,train accuracy:0.9921875\n",
      "epoch:838,loss:0.3203675150871277,train accuracy:0.96875\n",
      "epoch:839,loss:0.016256945207715034,train accuracy:0.9921875\n",
      "epoch:840,loss:0.33585402369499207,train accuracy:0.984375\n",
      "epoch 840,learning rate:0.00020849246173476125\n",
      "--epoch:840,loss:3.854454278945923,test accuracy:0.828125\n",
      "epoch:841,loss:3.368236139067449e-05,train accuracy:1.0\n",
      "epoch:842,loss:2.7640015105134808e-05,train accuracy:1.0\n",
      "epoch:843,loss:9.313225191043273e-10,train accuracy:1.0\n",
      "epoch:844,loss:0.01444405410438776,train accuracy:0.9921875\n",
      "epoch:845,loss:0.24671274423599243,train accuracy:0.9921875\n",
      "epoch 845,learning rate:0.00020640753711741362\n",
      "--epoch:845,loss:2.369833469390869,test accuracy:0.8515625\n",
      "epoch:846,loss:0.04567420855164528,train accuracy:0.9921875\n",
      "epoch:847,loss:0.05051787942647934,train accuracy:0.984375\n",
      "epoch:848,loss:0.03864132612943649,train accuracy:0.984375\n",
      "epoch:849,loss:0.15173999965190887,train accuracy:0.96875\n",
      "epoch:850,loss:0.09936236590147018,train accuracy:0.9921875\n",
      "epoch 850,learning rate:0.00020434346174623948\n",
      "--epoch:850,loss:3.003438711166382,test accuracy:0.84375\n",
      "epoch:851,loss:0.8121198415756226,train accuracy:0.984375\n",
      "epoch:852,loss:0.15294478833675385,train accuracy:0.9921875\n",
      "epoch:853,loss:0.05766431614756584,train accuracy:0.9921875\n",
      "epoch:854,loss:0.004492340609431267,train accuracy:1.0\n",
      "epoch:855,loss:2.4378657599299913e-06,train accuracy:1.0\n",
      "epoch 855,learning rate:0.00020230002712877707\n",
      "--epoch:855,loss:2.3461170196533203,test accuracy:0.8828125\n",
      "epoch:856,loss:0.0004217642417643219,train accuracy:1.0\n",
      "epoch:857,loss:0.3972758650779724,train accuracy:0.9765625\n",
      "epoch:858,loss:0.07284269481897354,train accuracy:0.9921875\n",
      "epoch:859,loss:0.10776962339878082,train accuracy:0.9921875\n",
      "epoch:860,loss:0.05973542109131813,train accuracy:0.984375\n",
      "epoch 860,learning rate:0.0002002770268574893\n",
      "--epoch:860,loss:2.5438175201416016,test accuracy:0.8515625\n",
      "epoch:861,loss:0.16706104576587677,train accuracy:0.984375\n",
      "epoch:862,loss:0.4589231014251709,train accuracy:0.9765625\n",
      "epoch:863,loss:0.20592305064201355,train accuracy:0.9921875\n",
      "epoch:864,loss:0.0014481061371043324,train accuracy:1.0\n",
      "epoch:865,loss:1.8626449271863521e-09,train accuracy:1.0\n",
      "epoch 865,learning rate:0.00019827425658891441\n",
      "--epoch:865,loss:4.218011856079102,test accuracy:0.8125\n",
      "epoch:866,loss:0.0004037256585434079,train accuracy:1.0\n",
      "epoch:867,loss:0.13835594058036804,train accuracy:0.9921875\n",
      "epoch:868,loss:0.05655546113848686,train accuracy:0.9921875\n",
      "epoch:869,loss:0.14057320356369019,train accuracy:0.9921875\n",
      "epoch:870,loss:0.14241908490657806,train accuracy:0.9921875\n",
      "epoch 870,learning rate:0.00019629151402302526\n",
      "--epoch:870,loss:2.947197914123535,test accuracy:0.875\n",
      "epoch:871,loss:3.427842602832243e-05,train accuracy:1.0\n",
      "epoch:872,loss:0.2772766351699829,train accuracy:0.984375\n",
      "epoch:873,loss:2.0291936380090192e-05,train accuracy:1.0\n",
      "epoch:874,loss:0.03473282232880592,train accuracy:0.9921875\n",
      "epoch:875,loss:0.4891320466995239,train accuracy:0.953125\n",
      "epoch 875,learning rate:0.000194328598882795\n",
      "--epoch:875,loss:2.836498260498047,test accuracy:0.8671875\n",
      "epoch:876,loss:0.05517110228538513,train accuracy:0.9921875\n",
      "epoch:877,loss:0.5036388635635376,train accuracy:0.984375\n",
      "epoch:878,loss:0.19075027108192444,train accuracy:0.984375\n",
      "epoch:879,loss:0.005058435723185539,train accuracy:1.0\n",
      "epoch:880,loss:0.3849892318248749,train accuracy:0.984375\n",
      "epoch 880,learning rate:0.00019238531289396705\n",
      "--epoch:880,loss:3.2725634574890137,test accuracy:0.84375\n",
      "epoch:881,loss:0.01968345232307911,train accuracy:0.9921875\n",
      "epoch:882,loss:2.803240590765199e-07,train accuracy:1.0\n",
      "epoch:883,loss:0.00685977702960372,train accuracy:0.9921875\n",
      "epoch:884,loss:5.1979252020828426e-05,train accuracy:1.0\n",
      "epoch:885,loss:0.08715558797121048,train accuracy:0.9921875\n",
      "epoch 885,learning rate:0.00019046145976502738\n",
      "--epoch:885,loss:3.142695426940918,test accuracy:0.8359375\n",
      "epoch:886,loss:0.00040620131767354906,train accuracy:1.0\n",
      "epoch:887,loss:0.0001924842654261738,train accuracy:1.0\n",
      "epoch:888,loss:0.12745501101016998,train accuracy:0.984375\n",
      "epoch:889,loss:0.04512966424226761,train accuracy:0.9921875\n",
      "epoch:890,loss:0.06533561646938324,train accuracy:0.984375\n",
      "epoch 890,learning rate:0.0001885568451673771\n",
      "--epoch:890,loss:2.9899227619171143,test accuracy:0.859375\n",
      "epoch:891,loss:0.3046894967556,train accuracy:0.984375\n",
      "epoch:892,loss:0.22578662633895874,train accuracy:0.9609375\n",
      "epoch:893,loss:0.0012244607787579298,train accuracy:1.0\n",
      "epoch:894,loss:0.5340402126312256,train accuracy:0.9765625\n",
      "epoch:895,loss:4.85210591705254e-07,train accuracy:1.0\n",
      "--epoch:895,loss:4.0873541831970215,test accuracy:0.796875\n",
      "epoch:896,loss:0.13099218904972076,train accuracy:0.9921875\n",
      "epoch:897,loss:0.00022242309933062643,train accuracy:1.0\n",
      "epoch:898,loss:0.1453266441822052,train accuracy:0.984375\n",
      "epoch:899,loss:0.5517134666442871,train accuracy:0.9765625\n",
      "epoch:900,loss:9.396540008310694e-07,train accuracy:1.0\n",
      "epoch 900,learning rate:0.00018667127671570332\n",
      "--epoch:900,loss:1.981958031654358,test accuracy:0.90625\n",
      "epoch:901,loss:0.05512074753642082,train accuracy:0.984375\n",
      "epoch:902,loss:0.10914846509695053,train accuracy:0.984375\n",
      "epoch:903,loss:0.07308733463287354,train accuracy:0.984375\n",
      "epoch:904,loss:0.20892438292503357,train accuracy:0.9921875\n",
      "epoch:905,loss:0.1399487853050232,train accuracy:0.9921875\n",
      "epoch 905,learning rate:0.00018480456394854628\n",
      "--epoch:905,loss:4.819010257720947,test accuracy:0.8125\n",
      "epoch:906,loss:0.041630957275629044,train accuracy:0.9921875\n",
      "epoch:907,loss:0.00026311722467653453,train accuracy:1.0\n",
      "epoch:908,loss:5.963446164969355e-05,train accuracy:1.0\n",
      "epoch:909,loss:0.300527960062027,train accuracy:0.9765625\n",
      "epoch:910,loss:0.33437201380729675,train accuracy:0.9921875\n",
      "epoch 910,learning rate:0.0001829565183090608\n",
      "--epoch:910,loss:2.5743298530578613,test accuracy:0.84375\n",
      "epoch:911,loss:0.018007125705480576,train accuracy:0.9921875\n",
      "epoch:912,loss:0.24557116627693176,train accuracy:0.9921875\n",
      "epoch:913,loss:0.1760546714067459,train accuracy:0.9921875\n",
      "epoch:914,loss:0.06751210987567902,train accuracy:0.9921875\n",
      "epoch:915,loss:0.001432232209481299,train accuracy:1.0\n",
      "epoch 915,learning rate:0.0001811269531259702\n",
      "--epoch:915,loss:3.297100067138672,test accuracy:0.875\n",
      "epoch:916,loss:1.7330688706351793e-06,train accuracy:1.0\n",
      "epoch:917,loss:0.16466115415096283,train accuracy:0.9921875\n",
      "epoch:918,loss:0.1612175554037094,train accuracy:0.9921875\n",
      "epoch:919,loss:0.021726729348301888,train accuracy:0.9921875\n",
      "epoch:920,loss:0.4690508246421814,train accuracy:0.9921875\n",
      "epoch 920,learning rate:0.0001793156835947105\n",
      "--epoch:920,loss:2.4461326599121094,test accuracy:0.859375\n",
      "epoch:921,loss:0.0003983396745752543,train accuracy:1.0\n",
      "epoch:922,loss:0.2183414101600647,train accuracy:0.9765625\n",
      "epoch:923,loss:0.06845129281282425,train accuracy:0.9921875\n",
      "epoch:924,loss:0.0066182855516672134,train accuracy:0.9921875\n",
      "epoch:925,loss:0.2120237797498703,train accuracy:0.9921875\n",
      "epoch 925,learning rate:0.0001775225267587634\n",
      "--epoch:925,loss:2.892164945602417,test accuracy:0.8671875\n",
      "epoch:926,loss:0.23642683029174805,train accuracy:0.984375\n",
      "epoch:927,loss:0.6473129391670227,train accuracy:0.9609375\n",
      "epoch:928,loss:0.03905079513788223,train accuracy:0.9921875\n",
      "epoch:929,loss:0.3733188509941101,train accuracy:0.9765625\n",
      "epoch:930,loss:0.2253562957048416,train accuracy:0.9921875\n",
      "epoch 930,learning rate:0.00017574730149117577\n",
      "--epoch:930,loss:3.1163923740386963,test accuracy:0.8125\n",
      "epoch:931,loss:0.3418744206428528,train accuracy:0.984375\n",
      "epoch:932,loss:0.3032153248786926,train accuracy:0.9921875\n",
      "epoch:933,loss:0.09063367545604706,train accuracy:0.9765625\n",
      "epoch:934,loss:0.12398647516965866,train accuracy:0.984375\n",
      "epoch:935,loss:0.0,train accuracy:1.0\n",
      "epoch 935,learning rate:0.000173989828476264\n",
      "--epoch:935,loss:4.913235187530518,test accuracy:0.8125\n",
      "epoch:936,loss:0.04776463285088539,train accuracy:0.984375\n",
      "epoch:937,loss:0.2201962172985077,train accuracy:0.9921875\n",
      "epoch:938,loss:0.0030552037060260773,train accuracy:1.0\n",
      "epoch:939,loss:0.2480751872062683,train accuracy:0.9765625\n",
      "epoch:940,loss:0.34486714005470276,train accuracy:0.984375\n",
      "epoch 940,learning rate:0.00017224993019150138\n",
      "--epoch:940,loss:4.314104080200195,test accuracy:0.8359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:941,loss:0.003450306598097086,train accuracy:1.0\n",
      "epoch:942,loss:0.0005844201077707112,train accuracy:1.0\n",
      "epoch:943,loss:0.0003197983023710549,train accuracy:1.0\n",
      "epoch:944,loss:0.00023654369579162449,train accuracy:1.0\n",
      "epoch:945,loss:0.04183729737997055,train accuracy:0.9921875\n",
      "epoch 945,learning rate:0.00017052743088958637\n",
      "--epoch:945,loss:6.325770854949951,test accuracy:0.8046875\n",
      "epoch:946,loss:0.40898868441581726,train accuracy:0.9921875\n",
      "epoch:947,loss:0.2204410284757614,train accuracy:0.984375\n",
      "epoch:948,loss:2.8959813789697364e-05,train accuracy:1.0\n",
      "epoch:949,loss:0.18559543788433075,train accuracy:0.96875\n",
      "epoch:950,loss:0.0818776786327362,train accuracy:0.9921875\n",
      "epoch 950,learning rate:0.0001688221565806905\n",
      "--epoch:950,loss:4.270170211791992,test accuracy:0.8359375\n",
      "epoch:951,loss:0.2550261318683624,train accuracy:0.984375\n",
      "epoch:952,loss:1.728393044686527e-06,train accuracy:1.0\n",
      "epoch:953,loss:0.105906642973423,train accuracy:0.9921875\n",
      "epoch:954,loss:0.4919532835483551,train accuracy:0.984375\n",
      "epoch:955,loss:0.11905548721551895,train accuracy:0.9921875\n",
      "epoch 955,learning rate:0.0001671339350148836\n",
      "--epoch:955,loss:3.4503438472747803,test accuracy:0.8515625\n",
      "epoch:956,loss:0.011030296795070171,train accuracy:0.9921875\n",
      "epoch:957,loss:6.407239538930298e-07,train accuracy:1.0\n",
      "epoch:958,loss:0.05039418116211891,train accuracy:0.9921875\n",
      "epoch:959,loss:1.7162390122393845e-06,train accuracy:1.0\n",
      "epoch:960,loss:0.1538885086774826,train accuracy:0.9921875\n",
      "epoch 960,learning rate:0.00016546259566473478\n",
      "--epoch:960,loss:6.879746437072754,test accuracy:0.8125\n",
      "epoch:961,loss:0.05445282906293869,train accuracy:0.9921875\n",
      "epoch:962,loss:0.4180460274219513,train accuracy:0.984375\n",
      "epoch:963,loss:0.022611521184444427,train accuracy:0.9921875\n",
      "epoch:964,loss:0.28121304512023926,train accuracy:0.984375\n",
      "epoch:965,loss:0.29347217082977295,train accuracy:0.984375\n",
      "epoch 965,learning rate:0.00016380796970808743\n",
      "--epoch:965,loss:3.9993934631347656,test accuracy:0.859375\n",
      "epoch:966,loss:0.5782650113105774,train accuracy:0.9765625\n",
      "epoch:967,loss:0.09037189185619354,train accuracy:0.9921875\n",
      "epoch:968,loss:0.026586301624774933,train accuracy:0.9921875\n",
      "epoch:969,loss:0.08094865828752518,train accuracy:0.9921875\n",
      "epoch:970,loss:5.233857791608898e-07,train accuracy:1.0\n",
      "epoch 970,learning rate:0.00016216989001100656\n",
      "--epoch:970,loss:4.241276264190674,test accuracy:0.8203125\n",
      "epoch:971,loss:0.024841444566845894,train accuracy:0.984375\n",
      "epoch:972,loss:0.0394759327173233,train accuracy:0.9921875\n",
      "epoch:973,loss:0.16489391028881073,train accuracy:0.984375\n",
      "epoch:974,loss:0.2010149359703064,train accuracy:0.984375\n",
      "epoch:975,loss:0.2156459093093872,train accuracy:0.9921875\n",
      "epoch 975,learning rate:0.0001605481911108965\n",
      "--epoch:975,loss:3.0196285247802734,test accuracy:0.859375\n",
      "epoch:976,loss:0.3495722711086273,train accuracy:0.984375\n",
      "epoch:977,loss:0.09610795974731445,train accuracy:0.9921875\n",
      "epoch:978,loss:0.06700510531663895,train accuracy:0.984375\n",
      "epoch:979,loss:0.1631961166858673,train accuracy:0.984375\n",
      "epoch:980,loss:0.13471479713916779,train accuracy:0.9921875\n",
      "epoch 980,learning rate:0.00015894270919978754\n",
      "--epoch:980,loss:4.7171125411987305,test accuracy:0.84375\n",
      "epoch:981,loss:3.5158940590918064e-05,train accuracy:1.0\n",
      "epoch:982,loss:0.1646568775177002,train accuracy:0.984375\n",
      "epoch:983,loss:0.2700047791004181,train accuracy:0.9921875\n",
      "epoch:984,loss:0.37901434302330017,train accuracy:0.984375\n",
      "epoch:985,loss:0.1488126814365387,train accuracy:0.984375\n",
      "epoch 985,learning rate:0.00015735328210778968\n",
      "--epoch:985,loss:2.7647173404693604,test accuracy:0.875\n",
      "epoch:986,loss:0.10657867044210434,train accuracy:0.9921875\n",
      "epoch:987,loss:0.17767155170440674,train accuracy:0.984375\n",
      "epoch:988,loss:0.3104255199432373,train accuracy:0.9921875\n",
      "epoch:989,loss:6.5192553577730905e-09,train accuracy:1.0\n",
      "epoch:990,loss:0.0014289985410869122,train accuracy:1.0\n",
      "epoch 990,learning rate:0.0001557797492867118\n",
      "--epoch:990,loss:3.9703078269958496,test accuracy:0.84375\n",
      "epoch:991,loss:0.4289810359477997,train accuracy:0.984375\n",
      "epoch:992,loss:2.5393039777554804e-06,train accuracy:1.0\n",
      "epoch:993,loss:0.6458315253257751,train accuracy:0.984375\n",
      "epoch:994,loss:0.5563689470291138,train accuracy:0.9765625\n",
      "epoch:995,loss:9.313220417084267e-09,train accuracy:1.0\n",
      "epoch 995,learning rate:0.00015422195179384468\n",
      "--epoch:995,loss:4.962821960449219,test accuracy:0.8125\n",
      "epoch:996,loss:5.68105917864159e-08,train accuracy:1.0\n",
      "epoch:997,loss:0.6636162400245667,train accuracy:0.9765625\n",
      "epoch:998,loss:0.6806576251983643,train accuracy:0.96875\n",
      "epoch:999,loss:0.024345530197024345,train accuracy:0.9921875\n"
     ]
    }
   ],
   "source": [
    "kp_te,kp_tr=1.,0.5\n",
    "sess.run(init)\n",
    "lr=1e-3\n",
    "for i in range(1000):\n",
    "    mask=np.random.choice(TR_IMG.shape[0],128,replace=False)\n",
    "    x_,y_=TR_IMG[mask],TR_LAB[mask]\n",
    "    \n",
    "    loss_,acc_,m_=sess.run([loss,accuracy,merge],feed_dict={X:x_,Y:y_,KEEP_PROB:kp_tr,LEARNRATE:lr})\n",
    "    writer.add_summary(m_)\n",
    "    print('epoch:{},loss:{},train accuracy:{}'.format(i,loss_,acc_))\n",
    "    for j in range(10):\n",
    "        sess.run(trainer,feed_dict={X:x_,Y:y_,KEEP_PROB:kp_tr,LEARNRATE:lr})\n",
    "    if i%5==0:\n",
    "        mask=np.random.choice(TE_IMG.shape[0],128,replace=False)\n",
    "        x_,y_=TE_IMG[mask],TE_LAB[mask]\n",
    "        loss_,acc_,m_=sess.run([loss,accuracy,merge],feed_dict={X:x_,Y:y_,KEEP_PROB:kp_te})\n",
    "        writer_.add_summary(m_)\n",
    "        if acc_>0.8:\n",
    "            lr=max(0.99*lr,1e-5)\n",
    "            print ('epoch {},learning rate:{}'.format(i,lr))\n",
    "        print('--epoch:{},loss:{},test accuracy:{}'.format(i,loss_,acc_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer.close()\n",
    "writer_.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
